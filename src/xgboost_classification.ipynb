{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc6c082-1c90-441e-86e3-d01e665920e5",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e13c0d-5a7c-4405-81e0-4f2bf1d150f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/hookvan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb36e5e-c2ed-4101-8890-359849c4043c",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "254648ac-7e62-441b-9d0c-37e95c442198",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = os.listdir(\"../data_raw/topics\")\n",
    "df_topics_list = []\n",
    "for topic in topics:\n",
    "    files = os.listdir(f\"../data_raw/topics/{topic}\")\n",
    "    df_topic = pd.DataFrame(columns=[\"poem\", \"labels\"])\n",
    "    i = 0\n",
    "    for filename in files:\n",
    "        with open(f\"../data_raw/topics/{topic}/{filename}\", encoding=\"utf8\") as f:\n",
    "            df_topic.loc[i] = {\"poem\": f.read(), \"labels\": topic}\n",
    "        i += 1\n",
    "    df_topics_list.append(df_topic)\n",
    "\n",
    "df_topics = pd.concat(df_topics_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e138f520-d61e-4b07-a54d-a0dcff5d8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "df = df_topics\n",
    "df[\"poem\"] = df[\"poem\"].str.replace(\"\\n\", \" \").str.lower().str.translate(str.maketrans('', '', string.punctuation + \"‘’\")).replace(\"\\d+\",  \"\", regex=True)\n",
    "df[\"poem\"] = df[\"poem\"].apply(lambda poem: \" \".join([word for word in poem.split() if word not in stop_words]))\n",
    "df = df[df[\"poem\"].str.len() > 20].reset_index(drop=True)\n",
    "indices_to_remove = [3992, 9431, 11216, 12517, 12604]\n",
    "df = df.drop(indices_to_remove).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c6455eb1-e3e5-45c9-8768-dbd37fc0fbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>though watched many mourners weep oer real dea...</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hope timid friend sat without grated den watch...</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hope lies tomorrow betrayed yesterday every ne...</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dont give hope dont give hope still whole slew...</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>remember hope goes long way long little still ...</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14288</th>\n",
       "      <td>left dump cafe ankling need hack im johnnie wa...</td>\n",
       "      <td>chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14289</th>\n",
       "      <td>got name people say cuz el train tracks went r...</td>\n",
       "      <td>chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14290</th>\n",
       "      <td>tidy house dust especially living room forget ...</td>\n",
       "      <td>chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14291</th>\n",
       "      <td>bridges chicago bridges paris bridges amsterda...</td>\n",
       "      <td>chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14292</th>\n",
       "      <td>hello mawe stil alive listening still shadow a...</td>\n",
       "      <td>chicago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14293 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    poem   labels\n",
       "0      though watched many mourners weep oer real dea...     hope\n",
       "1      hope timid friend sat without grated den watch...     hope\n",
       "2      hope lies tomorrow betrayed yesterday every ne...     hope\n",
       "3      dont give hope dont give hope still whole slew...     hope\n",
       "4      remember hope goes long way long little still ...     hope\n",
       "...                                                  ...      ...\n",
       "14288  left dump cafe ankling need hack im johnnie wa...  chicago\n",
       "14289  got name people say cuz el train tracks went r...  chicago\n",
       "14290  tidy house dust especially living room forget ...  chicago\n",
       "14291  bridges chicago bridges paris bridges amsterda...  chicago\n",
       "14292  hello mawe stil alive listening still shadow a...  chicago\n",
       "\n",
       "[14293 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6ea1864-592a-4c6d-a93f-e475b3bf87f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>though watched many mourners weep oer real dea...</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hope timid friend sat without grated den watch...</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hope lies tomorrow betrayed yesterday every ne...</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dont give hope dont give hope still whole slew...</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>remember hope goes long way long little still ...</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14288</th>\n",
       "      <td>left dump cafe ankling need hack im johnnie wa...</td>\n",
       "      <td>chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14289</th>\n",
       "      <td>got name people say cuz el train tracks went r...</td>\n",
       "      <td>chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14290</th>\n",
       "      <td>tidy house dust especially living room forget ...</td>\n",
       "      <td>chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14291</th>\n",
       "      <td>bridges chicago bridges paris bridges amsterda...</td>\n",
       "      <td>chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14292</th>\n",
       "      <td>hello mawe stil alive listening still shadow a...</td>\n",
       "      <td>chicago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14293 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    poem   labels\n",
       "0      though watched many mourners weep oer real dea...     hope\n",
       "1      hope timid friend sat without grated den watch...     hope\n",
       "2      hope lies tomorrow betrayed yesterday every ne...     hope\n",
       "3      dont give hope dont give hope still whole slew...     hope\n",
       "4      remember hope goes long way long little still ...     hope\n",
       "...                                                  ...      ...\n",
       "14288  left dump cafe ankling need hack im johnnie wa...  chicago\n",
       "14289  got name people say cuz el train tracks went r...  chicago\n",
       "14290  tidy house dust especially living room forget ...  chicago\n",
       "14291  bridges chicago bridges paris bridges amsterda...  chicago\n",
       "14292  hello mawe stil alive listening still shadow a...  chicago\n",
       "\n",
       "[14293 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df #.groupby('labels').head(20)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bff277f3-f2ad-4d08-9c2c-9c07528c23ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['alone', 'america', 'angel', 'anger', 'animal', 'baby', 'beach',\n",
       "        'beautiful', 'beauty', 'believe', 'birth', 'brother', 'butterfly',\n",
       "        'car', 'carpe diem', 'change', 'chicago', 'childhood', 'children',\n",
       "        'christmas', 'cinderella', 'city', 'courage', 'crazy', 'culture',\n",
       "        'dance', 'dark', 'daughter', 'death', 'depression', 'despair',\n",
       "        'destiny', 'dream', 'evil', 'faith', 'family', 'father', 'fear',\n",
       "        'fire', 'food', 'football', 'freedom', 'friend', 'frog', 'funeral',\n",
       "        'funny', 'future', 'girl', 'god', 'graduation', 'greed', 'green',\n",
       "        'hair', 'happiness', 'happy', 'hate', 'heaven', 'hero', 'home',\n",
       "        'hope', 'house', 'hunting', 'husband', 'identity', 'innocence',\n",
       "        'january', 'joy', 'june', 'justice', 'kiss', 'laughter', 'life',\n",
       "        'lonely', 'loss', 'lost', 'love', 'lust', 'marriage', 'memory',\n",
       "        'mirror', 'money', 'moon', 'mother', 'murder', 'music', 'nature',\n",
       "        'night', 'ocean', 'paris', 'passion', 'peace', 'pink', 'poem',\n",
       "        'poetry', 'poverty', 'power', 'racism', 'rain', 'rainbow', 'red',\n",
       "        'remember', 'respect', 'river', 'romance', 'romantic', 'rose',\n",
       "        'running', 'school', 'sea', 'sick', 'silver', 'sister', 'sky',\n",
       "        'sleep', 'snake', 'soldier', 'sometimes', 'son', 'song', 'sorrow',\n",
       "        'spring', 'star', 'success', 'suicide', 'summer', 'sun',\n",
       "        'swimming', 'sympathy', 'teacher', 'thanks', 'time', 'today',\n",
       "        'together', 'travel', 'trust', 'truth', 'war', 'warning', 'water',\n",
       "        'weather', 'wedding', 'winter', 'work', 'world'], dtype=object),\n",
       " array([100, 100, 100,  98,  99, 100,  99, 100,  99,  99, 100, 100, 100,\n",
       "         97,  99,  99,  98,  98, 100, 100, 100,  99,  98, 100,  98, 100,\n",
       "        100,  98,  99,  99,  99,  98, 100,  96,  98, 100,  99,  99, 100,\n",
       "         97,  99,  98, 100,  99,  99, 100, 100,  99, 100, 100, 100,  98,\n",
       "         98, 100, 100, 100, 100, 100, 100,  99,  98,  99,  99,  98,  98,\n",
       "        100, 100, 100, 100, 100,  99, 100, 100,  99,  98,  99, 100, 100,\n",
       "        100, 100,  99, 100, 100,  97,  99,  99, 100,  99,  99, 100, 100,\n",
       "         99, 100, 100,  99, 100, 100,  99, 100,  99,  99,  99, 100, 100,\n",
       "        100,  99,  96, 100,  98,  99,  99,  98, 100,  99, 100, 100,  99,\n",
       "         99,  99,  99,  99,  98,  99,  99,  98, 100, 100, 100, 100, 100,\n",
       "        100, 100, 100,  99,  99,  99, 100, 100,  99,  99,  99, 100,  99,\n",
       "         99]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(filtered_df['labels'], return_counts =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b17970ff-d958-45ae-a104-00f2ace63522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hours laying bed almost time get work head im laughing wishing fantasy finally choosing really want every second relive moments enjoying every second heard love forever since smile ever lasted face ever come close every taken place times seems pointless like never meant times wait see still wait hang slim glimpse hope losing something couldnt cope years past seasons came went thoughts sleepless nights spent even day still remember first kiss still love love always miss'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df[filtered_df['labels'] == 'love']['poem'].iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078ec49-932f-4aac-8892-ab8eb707f90f",
   "metadata": {},
   "source": [
    "# XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c77a1cba-4d1e-4ae7-99e0-3750dcd666e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = CountVectorizer()\n",
    "#X = vectorizer.fit_transform(filtered_df['poem'])\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000) \n",
    "X = tfidf_vectorizer.fit_transform(filtered_df['poem'])\n",
    "\n",
    "\n",
    "# encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(filtered_df['labels'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cddda34-c137-47e3-8d32-9fad19c88e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c650f-1a72-4212-88a4-64af21824857",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_poem = [\"I miss you \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b440a4-caaa-4ec6-a92f-e46a49c04b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_poem_transformed = tfidf_vectorizer.transform(new_poem)\n",
    "predicted_label = model.predict(new_poem_transformed)\n",
    "\n",
    "predicted_label_decoded = label_encoder.inverse_transform(predicted_label)\n",
    "print(\"Predicted Label:\", predicted_label_decoded[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c24837-f899-465d-9c1a-a5b1a4646045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probs of all labels ( for multilabel?)\n",
    "\n",
    "probabilities = model.predict_proba(new_poem_transformed)\n",
    "labels = label_encoder.classes_\n",
    "\n",
    "prob_dict = {label: prob for label, prob in zip(labels, probabilities[0])}\n",
    "\n",
    "sorted_probabilities = sorted(prob_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print probabilities for each label in descending order\n",
    "for label, probability in sorted_probabilities:\n",
    "    print(f\"Probability of '{label}': {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f19db-5eac-4d3c-8913-a9070697c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab62e1-f2fe-4b64-ae52-0c01f5b83b6a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# XGBOOST + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b42e612c-91e4-4d30-b302-84d9dabd0823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.295126   -0.05824259  0.42334542 ... -0.50325745  0.32414806\n",
      "  -0.1545983 ]\n",
      " [ 0.11506277 -0.17986692  0.23144366 ... -0.5288107   0.31901187\n",
      "  -0.22553356]\n",
      " [ 0.07985287 -0.32657608 -0.17349988 ... -0.30127302  0.45985243\n",
      "  -0.19309199]\n",
      " ...\n",
      " [-0.07277451 -0.27822712 -0.08247866 ... -0.3087592   1.006625\n",
      "  -0.27042916]\n",
      " [-0.19649386 -0.30289686 -0.01229891 ... -0.43488362  0.68383104\n",
      "   0.07407475]\n",
      " [-0.25862762 -0.33636153  0.02183051 ... -0.37830243  0.90625334\n",
      "  -0.06640918]]\n",
      "[ 59  59 133 133  45  45  67  67  50  50  14  14 102 102  22  22  20  20\n",
      "  99  99 106 106 100 100 114 114  51  51  52  52  65  65 126 126 109 109\n",
      " 131 131  43  43   4   4  77  77  13  13  34  34  29  29   0   0  37  37\n",
      " 138 138 110 110 121 121  58  58  62  62   9   9  91  91  90  90 113 113\n",
      " 132 132 142 142  44  44  98  98  28  28 136 136  83  83  68  68  18  18\n",
      "  69  69   3   3   5   5  40  40  26  26  10  10   7   7 120 120  76  76\n",
      "  49  49  75  75  54  54 122 122  63  63 130 130  57  57  92  92  60  60\n",
      "  56  56  80  80 116 116 135 135  41  41 141 141  81  81 107 107  27  27\n",
      "  64  64 101 101 104 104  25  25  32  32 108 108   6   6 139 139  61  61\n",
      " 115 115  17  17 112 112  42  42 111 111  89  89  72  72  48  48  88  88\n",
      "  79  79 137 137  71  71  33  33  85  85  47  47  15  15  55  55  93  93\n",
      " 124 124 127 127 123 123  73  73  94  94 143 143  39  39  19  19  53  53\n",
      "  31  31  46  46   2   2  95  95  82  82   8   8  84  84  66  66  86  86\n",
      "  36  36 134 134 128 128 140 140  97  97  23  23 118 118 103 103  35  35\n",
      "  74  74 119 119  70  70 105 105  11  11  30  30 129 129 117 117 125 125\n",
      "   1   1  21  21  12  12  78  78  24  24  38  38  87  87  96  96  16  16]\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = filtered_df.groupby('labels').head(2)  \n",
    "X = data['poem']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data['labels'])\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_length = 128 \n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(text)[:max_length] for text in X]\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(tokens) for tokens in tokenized_texts]\n",
    "input_ids = [ids[:max_length] + [0] * (max_length - len(ids)) for ids in input_ids]  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "model.eval()\n",
    "\n",
    "bert_embeddings = []\n",
    "batch_size = 8\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(input_ids), batch_size):\n",
    "        batch_input_ids = torch.tensor(input_ids[i:i+batch_size]).to(device)\n",
    "        outputs = model(batch_input_ids)\n",
    "        bert_embeddings.extend(outputs[0][:, 0, :].cpu().numpy()) \n",
    "\n",
    "X_features = np.array(bert_embeddings)\n",
    "print(X_features)\n",
    "print(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(np.unique(y)),\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "num_rounds = 100\n",
    "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# Predictions\n",
    "y_pred = xgb_model.predict(dtest)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f986d9d-76e5-4e2d-b250-a058622f382d",
   "metadata": {},
   "source": [
    "# XGBOOST test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8803183a-d6da-4120-a89e-bf47804953ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c56a92-1e77-4512-a6df-1f97c442cbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
