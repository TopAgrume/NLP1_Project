{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Légende\n",
    "* [Pré-traitement](#1)\n",
    "    * [Lowercase everything](#11)\n",
    "    * [Remove apostrophes](#12)\n",
    "    * [Remove \\r and \\n](#13)\n",
    "    * [Remove the punctuations](#14)\n",
    "    * [Remove stop word](#15)\n",
    "* [Part-of-speech tagging](#2) \n",
    "* [Data Augmentation](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-traitement <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "- Characters to lowercase\n",
    "- Remove apostrophes, whitespaces and punctuations\n",
    "- Adding tokens START, END and N to differentiate new lines and poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except:\n",
    "    print(\"Downloading nltk.stopwords...\")\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "# Download nltk packages for POS Tagging\n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "except LookupError:\n",
    "    print(\"Downloading nltk.averaged_perceptron_tagger...\")\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13851</th>\n",
       "      <td>\\r\\r\\n\\r\\r\\n</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13852</th>\n",
       "      <td>\\r\\r\\n          Philosophic\\r\\r\\nin its complex, ovoid emptiness,\\r\\r\\na skillful pundit coined it as a sort\\r\\r\\n    of stopgap doorstop for those\\r\\r\\n           quaint equations           Romans never\\r\\r\\ndreamt of. In form completely clever\\r\\r\\nand discrete—a mirror come unsilvered,     loose watch face without the works,              a hollowed globe            from tip to toe\\r\\r\\nunbroken, it evades the grappling\\r\\r\\nhooks of mass, tilts the thin rim of no thing,     remains embryonic sum,             non-cogito.\\r\\r\\n</td>\n",
       "      <td>Arts &amp; Sciences,Philosophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13853</th>\n",
       "      <td>\\r\\r\\nDear Writers, I’m compiling the first in what I hope is a series of publications I’m calling artists among artists. The theme for issue 1 is “Faggot Dinosaur.” I hope to hear from you! Thank you and best wishes.</td>\n",
       "      <td>Relationships,Gay, Lesbian, Queer,Arts &amp; Sciences,Poetry &amp; Poets,Social Commentaries,Gender &amp; Sexuality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         poem  \\\n",
       "13851                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \\r\\r\\n\\r\\r\\n   \n",
       "13852  \\r\\r\\n          Philosophic\\r\\r\\nin its complex, ovoid emptiness,\\r\\r\\na skillful pundit coined it as a sort\\r\\r\\n    of stopgap doorstop for those\\r\\r\\n           quaint equations           Romans never\\r\\r\\ndreamt of. In form completely clever\\r\\r\\nand discrete—a mirror come unsilvered,     loose watch face without the works,              a hollowed globe            from tip to toe\\r\\r\\nunbroken, it evades the grappling\\r\\r\\nhooks of mass, tilts the thin rim of no thing,     remains embryonic sum,             non-cogito.\\r\\r\\n   \n",
       "13853                                                                                                                                                                                                                                                                                                                             \\r\\r\\nDear Writers, I’m compiling the first in what I hope is a series of publications I’m calling artists among artists. The theme for issue 1 is “Faggot Dinosaur.” I hope to hear from you! Thank you and best wishes.     \n",
       "\n",
       "                                                                                                        labels  \n",
       "13851                                                                                                      NaN  \n",
       "13852                                                                               Arts & Sciences,Philosophy  \n",
       "13853  Relationships,Gay, Lesbian, Queer,Arts & Sciences,Poetry & Poets,Social Commentaries,Gender & Sexuality  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_PoetryFoundationData = pd.read_csv(\"../data_raw/PoetryFoundationData.csv\")\n",
    "df_PoetryFoundationData.drop(columns=[\"Title\", \"Poet\", \"Unnamed: 0\"], inplace=True)\n",
    "df_PoetryFoundationData.rename(columns={\"Poem\": \"poem\", \"Tags\": \"labels\"}, inplace=True)\n",
    "df_PoetryFoundationData.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poem        0\n",
       "labels    955\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_PoetryFoundationData.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercase everything <a class=\"anchor\" id=\"11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PoetryFoundationData[\"poem\"] = df_PoetryFoundationData[\"poem\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove apostrophes <a class=\"anchor\" id=\"12\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I remove the apostrophes and join the left and right parts. E.g. \"I'm\" -> \"Im\"\n",
    "df_PoetryFoundationData[\"poem\"] = df_PoetryFoundationData[\"poem\"].str.replace(\"'\", \"\", regex=False)\n",
    "df_PoetryFoundationData[\"poem\"] = df_PoetryFoundationData[\"poem\"].str.replace(\"’\", \"\", regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove \\r and \\n <a class=\"anchor\" id=\"13\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Adding tokens START, END and N (newline) for each poem\\ndf_PoetryFoundationData['poem'] = 'START ' + df_PoetryFoundationData['poem'] + ' END'\\ndf_PoetryFoundationData['poem'] = df_PoetryFoundationData['poem'].str.replace('\\n', ' N ')\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_PoetryFoundationData[\"poem\"] = df_PoetryFoundationData[\"poem\"].str.replace(\"\\r\", \"\")\n",
    "df_PoetryFoundationData[\"poem\"] = df_PoetryFoundationData[\"poem\"].str.strip(\"\\n\")\n",
    "df_PoetryFoundationData = df_PoetryFoundationData[df_PoetryFoundationData[\"poem\"] != \"\"]\n",
    "\n",
    "\"\"\"\n",
    "# Adding tokens START, END and N (newline) for each poem\n",
    "df_PoetryFoundationData['poem'] = 'START ' + df_PoetryFoundationData['poem'] + ' END'\n",
    "df_PoetryFoundationData['poem'] = df_PoetryFoundationData['poem'].str.replace('\\n', ' N ')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the punctuations <a class=\"anchor\" id=\"14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PoetryFoundationData[\"poem\"] = df_PoetryFoundationData[\"poem\"].str.replace(\"[^\\w\\s]\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop word <a class=\"anchor\" id=\"15\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))\n",
    "df_PoetryFoundationData[\"poem\"] = df_PoetryFoundationData[\"poem\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13835</th>\n",
       "      <td>dear writers im compiling first hope series publications im calling artists among artists theme issue 1 faggot dinosaur hope hear thank best wishes</td>\n",
       "      <td>Relationships,Gay, Lesbian, Queer,Arts &amp; Sciences,Poetry &amp; Poets,Social Commentaries,Gender &amp; Sexuality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13848</th>\n",
       "      <td>wise men unlearn name head star flame one weary sound hoarse roar gale shadows fall tired eyes lone bedside candle dies calendar breeds nights till stores candles fail prompts melancholy key long familiar melody sounds let let sound night let sound hour death gratefulness eyes lips sometimes makes us lift gaze far sky glare silence wall stocking gapes gifts clear old trust good saint nick late miracles suddenly lifting eyes heavens light realize life sheer gift</td>\n",
       "      <td>Living,Death,Growing Old,Time &amp; Brevity,Nature,Winter,New Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13849</th>\n",
       "      <td>wed like talk fear said many people live fear days drove four small car nice boy said beautiful dogs said friendly man ahead woman two waiting drive outside digging garden one home said selling anyway im interested said well nice day said heres card theres phone number call anytime houses road anyone else live wed like talk living fear</td>\n",
       "      <td>Living,Social Commentaries,Popular Culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13852</th>\n",
       "      <td>philosophic complex ovoid emptiness skillful pundit coined sort stopgap doorstop quaint equations romans never dreamt form completely clever discretea mirror come unsilvered loose watch face without works hollowed globe tip toe unbroken evades grappling hooks mass tilts thin rim thing remains embryonic sum noncogito</td>\n",
       "      <td>Arts &amp; Sciences,Philosophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13853</th>\n",
       "      <td>dear writers im compiling first hope series publications im calling artists among artists theme issue 1 faggot dinosaur hope hear thank best wishes</td>\n",
       "      <td>Relationships,Gay, Lesbian, Queer,Arts &amp; Sciences,Poetry &amp; Poets,Social Commentaries,Gender &amp; Sexuality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    poem  \\\n",
       "13835                                                                                                                                                                                                                                                                                                                                dear writers im compiling first hope series publications im calling artists among artists theme issue 1 faggot dinosaur hope hear thank best wishes   \n",
       "13848  wise men unlearn name head star flame one weary sound hoarse roar gale shadows fall tired eyes lone bedside candle dies calendar breeds nights till stores candles fail prompts melancholy key long familiar melody sounds let let sound night let sound hour death gratefulness eyes lips sometimes makes us lift gaze far sky glare silence wall stocking gapes gifts clear old trust good saint nick late miracles suddenly lifting eyes heavens light realize life sheer gift   \n",
       "13849                                                                                                                                  wed like talk fear said many people live fear days drove four small car nice boy said beautiful dogs said friendly man ahead woman two waiting drive outside digging garden one home said selling anyway im interested said well nice day said heres card theres phone number call anytime houses road anyone else live wed like talk living fear   \n",
       "13852                                                                                                                                                      philosophic complex ovoid emptiness skillful pundit coined sort stopgap doorstop quaint equations romans never dreamt form completely clever discretea mirror come unsilvered loose watch face without works hollowed globe tip toe unbroken evades grappling hooks mass tilts thin rim thing remains embryonic sum noncogito   \n",
       "13853                                                                                                                                                                                                                                                                                                                                dear writers im compiling first hope series publications im calling artists among artists theme issue 1 faggot dinosaur hope hear thank best wishes   \n",
       "\n",
       "                                                                                                        labels  \n",
       "13835  Relationships,Gay, Lesbian, Queer,Arts & Sciences,Poetry & Poets,Social Commentaries,Gender & Sexuality  \n",
       "13848                                           Living,Death,Growing Old,Time & Brevity,Nature,Winter,New Year  \n",
       "13849                                                               Living,Social Commentaries,Popular Culture  \n",
       "13852                                                                               Arts & Sciences,Philosophy  \n",
       "13853  Relationships,Gay, Lesbian, Queer,Arts & Sciences,Poetry & Poets,Social Commentaries,Gender & Sexuality  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_PoetryFoundationData.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-speech tagging <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/cricri/nltk_data'\n    - '/home/cricri/Desktop/EPITA_S8/my-env/nltk_data'\n    - '/home/cricri/Desktop/EPITA_S8/my-env/share/nltk_data'\n    - '/home/cricri/Desktop/EPITA_S8/my-env/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m poem_example \u001b[38;5;241m=\u001b[39m df_PoetryFoundationData[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoem\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoem_example\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      3\u001b[0m     wordtokens \u001b[38;5;241m=\u001b[39m word_tokenize(sent)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(nltk\u001b[38;5;241m.\u001b[39mpos_tag(wordtokens),end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/EPITA_S8/my-env/lib/python3.10/site-packages/nltk/tokenize/__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m~/Desktop/EPITA_S8/my-env/lib/python3.10/site-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m \u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/Desktop/EPITA_S8/my-env/lib/python3.10/site-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[0;32m~/Desktop/EPITA_S8/my-env/lib/python3.10/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/cricri/nltk_data'\n    - '/home/cricri/Desktop/EPITA_S8/my-env/nltk_data'\n    - '/home/cricri/Desktop/EPITA_S8/my-env/share/nltk_data'\n    - '/home/cricri/Desktop/EPITA_S8/my-env/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "poem_example = df_PoetryFoundationData[\"poem\"][0]\n",
    "for sent in sent_tokenize(poem_example):\n",
    "    wordtokens = word_tokenize(sent)\n",
    "    print(nltk.pos_tag(wordtokens),end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- stemming and lemmatization\n",
    "- rephrase text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
