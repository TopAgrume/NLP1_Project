{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams\n",
    "\n",
    "## Import librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/akaagi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10061</th>\n",
       "      <td>i imagined the atmosphere would be clear,\\nshot with pristine light,\\nnot this sulphurous haze,\\nthe air ionized as before a thunderstorm.\\nmany have pictured a river here,\\nbut no one mentioned all the boats,\\ntheir benches crowded with naked passengers,\\neach bent over a writing tablet.\\ni knew i would not always be a child\\nwith a model train and a model tunnel,\\nand i knew i would not live forever,\\njumping all day through the hoop of myself.\\ni had heard about the journey to the other side\\nand the clink of the final coin\\nin the leather purse of the man holding the oar,\\nbut how could anyone have guessed\\nthat as soon as we arrived\\nwe would be asked to describe this place\\nand to include as much detail as possible\\nnot just the water, he insists,\\nrather the oily, fathomless, rat-happy water,\\nnot simply the shackles, but the rusty,\\niron, ankle-shredding shackles\\nand that our next assignment would be\\nto jot down, off the tops of our heads,\\nour thoughts and feelings about being dead,\\nnot really an assignment,\\nthe man rotating the oar keeps telling us\\nthink of it more as an exercise, he groans,\\nthink of writing as a process,\\na never-ending, infernal process,\\nand now the boats have become jammed together,\\nbow against stern, stern locked to bow,\\nand not a thing is moving, only our diligent pens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10062</th>\n",
       "      <td>miss nancy ellicott\\nstrode across the hills and broke them,\\nrode across the hills and broke them\\nthe barren new england hills\\nriding to hounds\\nover the cow-pasture.\\nmiss nancy ellicott smoked\\nand danced all the modern dances;\\nand her aunts were not quite sure how they felt about it,\\nbut they knew that it was modern.\\nupon the glazen shelves kept watch\\nmatthew and waldo, guardians of the faith,\\nthe army of unalterable law.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10063</th>\n",
       "      <td>in the dark we disappear, pure being.\\nour mirror images, impure being.\\nbeing and becoming heidegger, being and\\nnothingness sartrewhich is purer being?\\nbeing alone is no way to be thus\\nloneliness is the test of pure being.\\nnights in love i fell too far or not quite\\nfar enoughone pure, one impure being.\\nclouds, snow, mist, the dragon's breath on water,\\nsmoke from firea metaphor's pure being.\\nstillness and more stillness and the light locked\\ndeep insideboth pure and impure being.\\nis is the verb of being, i the noun\\nor pronoun for the purists of being.\\ni was, i am, i looked within and saw\\nnothing very clearly purest being.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      poem\n",
       "10061  i imagined the atmosphere would be clear,\\nshot with pristine light,\\nnot this sulphurous haze,\\nthe air ionized as before a thunderstorm.\\nmany have pictured a river here,\\nbut no one mentioned all the boats,\\ntheir benches crowded with naked passengers,\\neach bent over a writing tablet.\\ni knew i would not always be a child\\nwith a model train and a model tunnel,\\nand i knew i would not live forever,\\njumping all day through the hoop of myself.\\ni had heard about the journey to the other side\\nand the clink of the final coin\\nin the leather purse of the man holding the oar,\\nbut how could anyone have guessed\\nthat as soon as we arrived\\nwe would be asked to describe this place\\nand to include as much detail as possible\\nnot just the water, he insists,\\nrather the oily, fathomless, rat-happy water,\\nnot simply the shackles, but the rusty,\\niron, ankle-shredding shackles\\nand that our next assignment would be\\nto jot down, off the tops of our heads,\\nour thoughts and feelings about being dead,\\nnot really an assignment,\\nthe man rotating the oar keeps telling us\\nthink of it more as an exercise, he groans,\\nthink of writing as a process,\\na never-ending, infernal process,\\nand now the boats have become jammed together,\\nbow against stern, stern locked to bow,\\nand not a thing is moving, only our diligent pens.\n",
       "10062                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 miss nancy ellicott\\nstrode across the hills and broke them,\\nrode across the hills and broke them\\nthe barren new england hills\\nriding to hounds\\nover the cow-pasture.\\nmiss nancy ellicott smoked\\nand danced all the modern dances;\\nand her aunts were not quite sure how they felt about it,\\nbut they knew that it was modern.\\nupon the glazen shelves kept watch\\nmatthew and waldo, guardians of the faith,\\nthe army of unalterable law.\n",
       "10063                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    in the dark we disappear, pure being.\\nour mirror images, impure being.\\nbeing and becoming heidegger, being and\\nnothingness sartrewhich is purer being?\\nbeing alone is no way to be thus\\nloneliness is the test of pure being.\\nnights in love i fell too far or not quite\\nfar enoughone pure, one impure being.\\nclouds, snow, mist, the dragon's breath on water,\\nsmoke from firea metaphor's pure being.\\nstillness and more stillness and the light locked\\ndeep insideboth pure and impure being.\\nis is the verb of being, i the noun\\nor pronoun for the purists of being.\\ni was, i am, i looked within and saw\\nnothing very clearly purest being."
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"../../../data_raw/kaggle_poem_dataset.csv\")\n",
    "# df.drop(columns=[\"Unnamed: 0\", \"Author\", \"Title\", \"Poetry Foundation ID\"], inplace=True)\n",
    "# df.rename(columns={\"Content\": \"poem\"}, inplace=True)\n",
    "df = pd.read_csv(\"../../../data_raw/our_dataset.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\", \"topic\"], inplace=True)\n",
    "df.rename(columns={\"Content\": \"poem\"}, inplace=True)\n",
    "\n",
    "# Define the remove_non_english function\n",
    "def remove_non_english(text):\n",
    "    # Regular expression to remove non-English alphabet characters\n",
    "    english_only = re.sub(r'[^a-zA-Z\\s.,;?!\\'-]', '', text)\n",
    "    return english_only\n",
    "\n",
    "# Define the create_corpus function\n",
    "def create_corpus(text):\n",
    "    # Tokenize text into sentences\n",
    "    sentences = text.split('\\n')\n",
    "    # Remove empty strings\n",
    "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "    # Join sentences into a corpus\n",
    "    corpus = '\\n'.join(sentences)  # Keep newline characters\n",
    "    return corpus\n",
    "\n",
    "# Apply remove_non_english function to poem column\n",
    "df['poem'] = df['poem'].apply(remove_non_english)\n",
    "\n",
    "# Apply create_corpus function to poem column\n",
    "df['poem'] = df['poem'].apply(create_corpus)\n",
    "\n",
    "# Remove \\xa0\n",
    "df['poem'] = df['poem'].str.replace('\\xa0', '')\n",
    "\n",
    "# Apply lowercase to the poem column\n",
    "df['poem'] = df['poem'].str.lower()\n",
    "\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sunday we '"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \" \".join(df['poem'])\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in the training set: 3255376\n",
      "Vocabulary size: 128002\n"
     ]
    }
   ],
   "source": [
    "corpus = corpus.lower()\n",
    "tokens = word_tokenize(corpus)\n",
    "print(\"Number of tokens in the training set:\",len(tokens))\n",
    "\n",
    "vocab = set(tokens)\n",
    "print(\"Vocabulary size:\",len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Tokenize the input text.\"\"\"\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def count_ngrams(tokens, n):\n",
    "    \"\"\"Counts n-grams.\"\"\"\n",
    "    ngrams = [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "    return Counter(ngrams)\n",
    "\n",
    "def calculate_ngram_probabilities(df, column, n, k=0.00001):\n",
    "    \"\"\"Calculates n-gram probabilities.\"\"\"\n",
    "    train_tokens = \" \".join(df[column]).lower()\n",
    "    train_tokens = tokenize(train_tokens)\n",
    "    \n",
    "    vocab = set(train_tokens)\n",
    "    V = len(vocab)\n",
    "    ngram_counts = count_ngrams(train_tokens, n)\n",
    "    n_minus_one_gram_counts = count_ngrams(train_tokens, n-1)\n",
    "    ngram_probabilities = defaultdict(float)\n",
    "    \n",
    "    for ngram in ngram_counts:\n",
    "        prefix = ngram[:-1]\n",
    "        ngram_counts[ngram] += k\n",
    "        n_minus_one_gram_counts[prefix] += k\n",
    "        ngram_probabilities[ngram] = (ngram_counts[ngram] + k) / (n_minus_one_gram_counts[prefix] + k*V)\n",
    "\n",
    "    return ngram_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5  # n-gram size\n",
    "k = 0.00001  # Change this to the desired value for smoothing parameter k\n",
    "\n",
    "ngram_probabilities = calculate_ngram_probabilities(df, 'poem', n, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 5-grams: 3139732\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of {n}-grams:\",len(ngram_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {('sunday', 'we', 'lay', 'hands', 'on'): 0.43859949211194593,\n",
       "             ('we', 'lay', 'hands', 'on', 'a'): 0.43859949211194593,\n",
       "             ('lay', 'hands', 'on', 'a', 'girl'): 0.43859949211194593,\n",
       "             ('hands', 'on', 'a', 'girl', 'of'): 0.43859949211194593,\n",
       "             ('on', 'a', 'girl', 'of', 'ten'): 0.43859949211194593,\n",
       "             ('a', 'girl', 'of', 'ten', 'hand'): 0.43859949211194593,\n",
       "             ('girl', 'of', 'ten', 'hand', 'on'): 0.43859949211194593,\n",
       "             ('of', 'ten', 'hand', 'on', 'hand'): 0.43859949211194593,\n",
       "             ('ten', 'hand', 'on', 'hand', 'on'): 0.43859949211194593,\n",
       "             ('hand', 'on', 'hand', 'on', 'cornsilk'): 0.43859949211194593,\n",
       "             ('on', 'hand', 'on', 'cornsilk', 'hair'): 0.43859949211194593,\n",
       "             ('hand', 'on', 'cornsilk', 'hair', '.'): 0.43859949211194593,\n",
       "             ('on', 'cornsilk', 'hair', '.', 'we'): 0.43859949211194593,\n",
       "             ('cornsilk', 'hair', '.', 'we', 'sing'): 0.43859949211194593,\n",
       "             ('hair', '.', 'we', 'sing', 'the'): 0.43859949211194593,\n",
       "             ('.', 'we', 'sing', 'the', 'secret'): 0.43859949211194593,\n",
       "             ('we', 'sing', 'the', 'secret', 'language'): 0.43859949211194593,\n",
       "             ('sing',\n",
       "              'the',\n",
       "              'secret',\n",
       "              'language',\n",
       "              'sung'): 0.43859949211194593,\n",
       "             ('the', 'secret', 'language', 'sung', 'the'): 0.43859949211194593,\n",
       "             ('secret', 'language', 'sung', 'the', 'day'): 0.43859949211194593,\n",
       "             ('language', 'sung', 'the', 'day', 'the'): 0.43859949211194593,\n",
       "             ('sung', 'the', 'day', 'the', 'tin'): 0.43859949211194593,\n",
       "             ('the', 'day', 'the', 'tin', 'roof'): 0.43859949211194593,\n",
       "             ('day', 'the', 'tin', 'roof', 'of'): 0.43859949211194593,\n",
       "             ('the', 'tin', 'roof', 'of', 'the'): 0.43859949211194593,\n",
       "             ('tin', 'roof', 'of', 'the', 'tower'): 0.43859949211194593,\n",
       "             ('roof', 'of', 'the', 'tower', 'beat'): 0.43859949211194593,\n",
       "             ('of', 'the', 'tower', 'beat', 'on'): 0.43859949211194593,\n",
       "             ('the', 'tower', 'beat', 'on', 'gods'): 0.43859949211194593,\n",
       "             ('tower',\n",
       "              'beat',\n",
       "              'on',\n",
       "              'gods',\n",
       "              'floorboard'): 0.43859949211194593,\n",
       "             ('beat', 'on', 'gods', 'floorboard', 'he'): 0.43859949211194593,\n",
       "             ('on', 'gods', 'floorboard', 'he', 'got'): 0.43859949211194593,\n",
       "             ('gods', 'floorboard', 'he', 'got', 'cramp'): 0.43859949211194593,\n",
       "             ('floorboard', 'he', 'got', 'cramp', 'in'): 0.43859949211194593,\n",
       "             ('he', 'got', 'cramp', 'in', 'heaven'): 0.43859949211194593,\n",
       "             ('got', 'cramp', 'in', 'heaven', '.'): 0.43859949211194593,\n",
       "             ('cramp', 'in', 'heaven', '.', 'like'): 0.43859949211194593,\n",
       "             ('in', 'heaven', '.', 'like', 'our'): 0.43859949211194593,\n",
       "             ('heaven', '.', 'like', 'our', 'crying'): 0.43859949211194593,\n",
       "             ('.', 'like', 'our', 'crying', 'and'): 0.43859949211194593,\n",
       "             ('like', 'our', 'crying', 'and', 'our'): 0.43859949211194593,\n",
       "             ('our',\n",
       "              'crying',\n",
       "              'and',\n",
       "              'our',\n",
       "              'fornicating'): 0.43859949211194593,\n",
       "             ('crying',\n",
       "              'and',\n",
       "              'our',\n",
       "              'fornicating',\n",
       "              'so'): 0.43859949211194593,\n",
       "             ('and', 'our', 'fornicating', 'so', 'close'): 0.43859949211194593,\n",
       "             ('our', 'fornicating', 'so', 'close', 'to'): 0.43859949211194593,\n",
       "             ('fornicating', 'so', 'close', 'to', 'his'): 0.43859949211194593,\n",
       "             ('so', 'close', 'to', 'his', 'bed'): 0.43859949211194593,\n",
       "             ('close', 'to', 'his', 'bed', 'was'): 0.43859949211194593,\n",
       "             ('to', 'his', 'bed', 'was', 'so'): 0.43859949211194593,\n",
       "             ('his', 'bed', 'was', 'so', 'many'): 0.43859949211194593,\n",
       "             ('bed', 'was', 'so', 'many', 'shrill'): 0.43859949211194593,\n",
       "             ('was', 'so', 'many', 'shrill', 'mice'): 0.43859949211194593,\n",
       "             ('so', 'many', 'shrill', 'mice', 'in'): 0.43859949211194593,\n",
       "             ('many', 'shrill', 'mice', 'in', 'a'): 0.43859949211194593,\n",
       "             ('shrill', 'mice', 'in', 'a', 'pretty'): 0.43859949211194593,\n",
       "             ('mice', 'in', 'a', 'pretty', 'pine'): 0.43859949211194593,\n",
       "             ('in', 'a', 'pretty', 'pine', 'floor'): 0.43859949211194593,\n",
       "             ('a', 'pretty', 'pine', 'floor', '.'): 0.43859949211194593,\n",
       "             ('pretty', 'pine', 'floor', '.', 'to'): 0.43859949211194593,\n",
       "             ('pine', 'floor', '.', 'to', 'heal'): 0.43859949211194593,\n",
       "             ('floor', '.', 'to', 'heal', 'the'): 0.43859949211194593,\n",
       "             ('.', 'to', 'heal', 'the', 'girl'): 0.43859949211194593,\n",
       "             ('to', 'heal', 'the', 'girl', 'with'): 0.43859949211194593,\n",
       "             ('heal', 'the', 'girl', 'with', 'the'): 0.43859949211194593,\n",
       "             ('the', 'girl', 'with', 'the', 'crippled'): 0.15923809281165857,\n",
       "             ('girl', 'with', 'the', 'crippled', 'up'): 0.43859949211194593,\n",
       "             ('with', 'the', 'crippled', 'up', 'leg'): 0.43859949211194593,\n",
       "             ('the', 'crippled', 'up', 'leg', 'god'): 0.43859949211194593,\n",
       "             ('crippled', 'up', 'leg', 'god', 'sends'): 0.43859949211194593,\n",
       "             ('up', 'leg', 'god', 'sends', 'back'): 0.43859949211194593,\n",
       "             ('leg', 'god', 'sends', 'back', 'the'): 0.43859949211194593,\n",
       "             ('god', 'sends', 'back', 'the', 'song'): 0.43859949211194593,\n",
       "             ('sends', 'back', 'the', 'song', 'he'): 0.43859949211194593,\n",
       "             ('back', 'the', 'song', 'he', 'took'): 0.43859949211194593,\n",
       "             ('the', 'song', 'he', 'took', 'and'): 0.43859949211194593,\n",
       "             ('song', 'he', 'took', 'and', 'down'): 0.43859949211194593,\n",
       "             ('he', 'took', 'and', 'down', 'it'): 0.43859949211194593,\n",
       "             ('took', 'and', 'down', 'it', 'comes'): 0.43859949211194593,\n",
       "             ('and', 'down', 'it', 'comes', 'contrary'): 0.43859949211194593,\n",
       "             ('down', 'it', 'comes', 'contrary', 'in'): 0.43859949211194593,\n",
       "             ('it', 'comes', 'contrary', 'in', 'one'): 0.43859949211194593,\n",
       "             ('comes', 'contrary', 'in', 'one', 'mouth'): 0.43859949211194593,\n",
       "             ('contrary', 'in', 'one', 'mouth', 'as'): 0.43859949211194593,\n",
       "             ('in', 'one', 'mouth', 'as', 'fire'): 0.43859949211194593,\n",
       "             ('one', 'mouth', 'as', 'fire', 'gentle'): 0.43859949211194593,\n",
       "             ('mouth', 'as', 'fire', 'gentle', 'on'): 0.43859949211194593,\n",
       "             ('as', 'fire', 'gentle', 'on', 'our'): 0.43859949211194593,\n",
       "             ('fire', 'gentle', 'on', 'our', 'bodies'): 0.43859949211194593,\n",
       "             ('gentle', 'on', 'our', 'bodies', 'as'): 0.43859949211194593,\n",
       "             ('on', 'our', 'bodies', 'as', 'rain'): 0.43859949211194593,\n",
       "             ('our', 'bodies', 'as', 'rain', '.'): 0.43859949211194593,\n",
       "             ('bodies', 'as', 'rain', '.', 'soft'): 0.43859949211194593,\n",
       "             ('as', 'rain', '.', 'soft', 'rain'): 0.43859949211194593,\n",
       "             ('rain', '.', 'soft', 'rain', 'swells'): 0.43859949211194593,\n",
       "             ('.', 'soft', 'rain', 'swells', 'the'): 0.43859949211194593,\n",
       "             ('soft',\n",
       "              'rain',\n",
       "              'swells',\n",
       "              'the',\n",
       "              'cumberland'): 0.43859949211194593,\n",
       "             ('rain',\n",
       "              'swells',\n",
       "              'the',\n",
       "              'cumberland',\n",
       "              'and'): 0.43859949211194593,\n",
       "             ('swells',\n",
       "              'the',\n",
       "              'cumberland',\n",
       "              'and',\n",
       "              'all'): 0.43859949211194593,\n",
       "             ('the', 'cumberland', 'and', 'all', 'her'): 0.43859949211194593,\n",
       "             ('cumberland',\n",
       "              'and',\n",
       "              'all',\n",
       "              'her',\n",
       "              'fields'): 0.43859949211194593,\n",
       "             ('and', 'all', 'her', 'fields', 'in'): 0.43859949211194593,\n",
       "             ('all', 'her', 'fields', 'in', 'april'): 0.43859949211194593,\n",
       "             ('her', 'fields', 'in', 'april', 'nuzzles'): 0.43859949211194593,\n",
       "             ('fields',\n",
       "              'in',\n",
       "              'april',\n",
       "              'nuzzles',\n",
       "              'buttercups'): 0.43859949211194593,\n",
       "             ('in',\n",
       "              'april',\n",
       "              'nuzzles',\n",
       "              'buttercups',\n",
       "              'the'): 0.43859949211194593,\n",
       "             ('april',\n",
       "              'nuzzles',\n",
       "              'buttercups',\n",
       "              'the',\n",
       "              'mules'): 0.43859949211194593,\n",
       "             ('nuzzles',\n",
       "              'buttercups',\n",
       "              'the',\n",
       "              'mules',\n",
       "              'wont'): 0.43859949211194593,\n",
       "             ('buttercups',\n",
       "              'the',\n",
       "              'mules',\n",
       "              'wont',\n",
       "              'touch'): 0.43859949211194593,\n",
       "             ('the', 'mules', 'wont', 'touch', 'the'): 0.43859949211194593,\n",
       "             ('mules',\n",
       "              'wont',\n",
       "              'touch',\n",
       "              'the',\n",
       "              'crowpoison'): 0.43859949211194593,\n",
       "             ('wont',\n",
       "              'touch',\n",
       "              'the',\n",
       "              'crowpoison',\n",
       "              'the'): 0.43859949211194593,\n",
       "             ('touch',\n",
       "              'the',\n",
       "              'crowpoison',\n",
       "              'the',\n",
       "              'wake-robin'): 0.43859949211194593,\n",
       "             ('the',\n",
       "              'crowpoison',\n",
       "              'the',\n",
       "              'wake-robin',\n",
       "              'the'): 0.43859949211194593,\n",
       "             ('crowpoison',\n",
       "              'the',\n",
       "              'wake-robin',\n",
       "              'the',\n",
       "              'bluets'): 0.43859949211194593,\n",
       "             ('the', 'wake-robin', 'the', 'bluets', 'of'): 0.43859949211194593,\n",
       "             ('wake-robin', 'the', 'bluets', 'of', 'the'): 0.43859949211194593,\n",
       "             ('the', 'bluets', 'of', 'the', 'field'): 0.43859949211194593,\n",
       "             ('bluets', 'of', 'the', 'field', '.'): 0.43859949211194593,\n",
       "             ('of', 'the', 'field', '.', 'every'): 0.23364789499139027,\n",
       "             ('the', 'field', '.', 'every', 'song'): 0.43859949211194593,\n",
       "             ('field', '.', 'every', 'song', 'got'): 0.43859949211194593,\n",
       "             ('.', 'every', 'song', 'got', 'a'): 0.43859949211194593,\n",
       "             ('every', 'song', 'got', 'a', 'beat'): 0.43859949211194593,\n",
       "             ('song', 'got', 'a', 'beat', 'beneath'): 0.43859949211194593,\n",
       "             ('got', 'a', 'beat', 'beneath', '.'): 0.43859949211194593,\n",
       "             ('a', 'beat', 'beneath', '.', 'start'): 0.43859949211194593,\n",
       "             ('beat', 'beneath', '.', 'start', 'with'): 0.43859949211194593,\n",
       "             ('beneath', '.', 'start', 'with', 'the'): 0.43859949211194593,\n",
       "             ('.',\n",
       "              'start',\n",
       "              'with',\n",
       "              'the',\n",
       "              'whippoorwill'): 0.43859949211194593,\n",
       "             ('start',\n",
       "              'with',\n",
       "              'the',\n",
       "              'whippoorwill',\n",
       "              'early'): 0.43859949211194593,\n",
       "             ('with',\n",
       "              'the',\n",
       "              'whippoorwill',\n",
       "              'early',\n",
       "              'meadow'): 0.43859949211194593,\n",
       "             ('the',\n",
       "              'whippoorwill',\n",
       "              'early',\n",
       "              'meadow',\n",
       "              'colors'): 0.43859949211194593,\n",
       "             ('whippoorwill',\n",
       "              'early',\n",
       "              'meadow',\n",
       "              'colors',\n",
       "              'creep'): 0.43859949211194593,\n",
       "             ('early',\n",
       "              'meadow',\n",
       "              'colors',\n",
       "              'creep',\n",
       "              'into'): 0.43859949211194593,\n",
       "             ('meadow', 'colors', 'creep', 'into', 'the'): 0.43859949211194593,\n",
       "             ('colors', 'creep', 'into', 'the', 'sky'): 0.43859949211194593,\n",
       "             ('creep', 'into', 'the', 'sky', '.'): 0.43859949211194593,\n",
       "             ('into', 'the', 'sky', '.', 'my'): 0.15923809281165857,\n",
       "             ('the', 'sky', '.', 'my', 'sons'): 0.1893966511553912,\n",
       "             ('sky', '.', 'my', 'sons', 'made'): 0.43859949211194593,\n",
       "             ('.', 'my', 'sons', 'made', 'this'): 0.43859949211194593,\n",
       "             ('my', 'sons', 'made', 'this', 'tobacco'): 0.43859949211194593,\n",
       "             ('sons', 'made', 'this', 'tobacco', 'sled'): 0.43859949211194593,\n",
       "             ('made', 'this', 'tobacco', 'sled', 'i'): 0.43859949211194593,\n",
       "             ('this', 'tobacco', 'sled', 'i', 'prime'): 0.43859949211194593,\n",
       "             ('tobacco', 'sled', 'i', 'prime', 'with'): 0.43859949211194593,\n",
       "             ('sled', 'i', 'prime', 'with', 'the'): 0.43859949211194593,\n",
       "             ('i', 'prime', 'with', 'the', 'jenny'): 0.43859949211194593,\n",
       "             ('prime', 'with', 'the', 'jenny', 'toss'): 0.43859949211194593,\n",
       "             ('with', 'the', 'jenny', 'toss', 'the'): 0.43859949211194593,\n",
       "             ('the', 'jenny', 'toss', 'the', 'last'): 0.43859949211194593,\n",
       "             ('jenny', 'toss', 'the', 'last', 'of'): 0.43859949211194593,\n",
       "             ('toss', 'the', 'last', 'of', 'the'): 0.43859949211194593,\n",
       "             ('the', 'last', 'of', 'the', 'sandlugs'): 0.05787142730654982,\n",
       "             ('last', 'of', 'the', 'sandlugs', 'for'): 0.43859949211194593,\n",
       "             ('of', 'the', 'sandlugs', 'for', 'the'): 0.43859949211194593,\n",
       "             ('the', 'sandlugs', 'for', 'the', 'rest'): 0.43859949211194593,\n",
       "             ('sandlugs', 'for', 'the', 'rest', 'to'): 0.43859949211194593,\n",
       "             ('for', 'the', 'rest', 'to', 'thrive'): 0.43859949211194593,\n",
       "             ('the', 'rest', 'to', 'thrive', '.'): 0.43859949211194593,\n",
       "             ('rest', 'to', 'thrive', '.', 'so'): 0.43859949211194593,\n",
       "             ('to', 'thrive', '.', 'so', 'hot'): 0.43859949211194593,\n",
       "             ('thrive', '.', 'so', 'hot', 'the'): 0.43859949211194593,\n",
       "             ('.', 'so', 'hot', 'the', 'wasps'): 0.43859949211194593,\n",
       "             ('so', 'hot', 'the', 'wasps', 'hang'): 0.43859949211194593,\n",
       "             ('hot', 'the', 'wasps', 'hang', 'on'): 0.43859949211194593,\n",
       "             ('the', 'wasps', 'hang', 'on', 'the'): 0.43859949211194593,\n",
       "             ('wasps',\n",
       "              'hang',\n",
       "              'on',\n",
       "              'the',\n",
       "              'honeysuckle'): 0.43859949211194593,\n",
       "             ('hang', 'on', 'the', 'honeysuckle', 'too'): 0.43859949211194593,\n",
       "             ('on', 'the', 'honeysuckle', 'too', 'spent'): 0.43859949211194593,\n",
       "             ('the', 'honeysuckle', 'too', 'spent', 'to'): 0.43859949211194593,\n",
       "             ('honeysuckle',\n",
       "              'too',\n",
       "              'spent',\n",
       "              'to',\n",
       "              'buzz'): 0.43859949211194593,\n",
       "             ('too', 'spent', 'to', 'buzz', 'a'): 0.43859949211194593,\n",
       "             ('spent', 'to', 'buzz', 'a', 'sermon'): 0.43859949211194593,\n",
       "             ('to', 'buzz', 'a', 'sermon', '.'): 0.43859949211194593,\n",
       "             ('buzz', 'a', 'sermon', '.', 'i'): 0.43859949211194593,\n",
       "             ('a', 'sermon', '.', 'i', 'know'): 0.43859949211194593,\n",
       "             ('sermon', '.', 'i', 'know', 'my'): 0.43859949211194593,\n",
       "             ('.', 'i', 'know', 'my', 'song'): 0.08865401953718209,\n",
       "             ('i', 'know', 'my', 'song', 'remembers'): 0.43859949211194593,\n",
       "             ('know', 'my', 'song', 'remembers', 'what'): 0.43859949211194593,\n",
       "             ('my', 'song', 'remembers', 'what', 'my'): 0.43859949211194593,\n",
       "             ('song',\n",
       "              'remembers',\n",
       "              'what',\n",
       "              'my',\n",
       "              'fathers'): 0.43859949211194593,\n",
       "             ('remembers',\n",
       "              'what',\n",
       "              'my',\n",
       "              'fathers',\n",
       "              'told'): 0.43859949211194593,\n",
       "             ('what', 'my', 'fathers', 'told', 'their'): 0.43859949211194593,\n",
       "             ('my',\n",
       "              'fathers',\n",
       "              'told',\n",
       "              'their',\n",
       "              'strings'): 0.43859949211194593,\n",
       "             ('fathers', 'told', 'their', 'strings', '.'): 0.43859949211194593,\n",
       "             ('told',\n",
       "              'their',\n",
       "              'strings',\n",
       "              '.',\n",
       "              'driskill'): 0.43859949211194593,\n",
       "             ('their', 'strings', '.', 'driskill', ','): 0.43859949211194593,\n",
       "             ('strings',\n",
       "              '.',\n",
       "              'driskill',\n",
       "              ',',\n",
       "              'kentuckydriskill'): 0.43859949211194593,\n",
       "             ('.',\n",
       "              'driskill',\n",
       "              ',',\n",
       "              'kentuckydriskill',\n",
       "              ','): 0.43859949211194593,\n",
       "             ('driskill',\n",
       "              ',',\n",
       "              'kentuckydriskill',\n",
       "              ',',\n",
       "              'kentucky'): 0.43859949211194593,\n",
       "             (',',\n",
       "              'kentuckydriskill',\n",
       "              ',',\n",
       "              'kentucky',\n",
       "              'o'): 0.43859949211194593,\n",
       "             ('kentuckydriskill',\n",
       "              ',',\n",
       "              'kentucky',\n",
       "              'o',\n",
       "              'transientvoyager'): 0.43859949211194593,\n",
       "             (',',\n",
       "              'kentucky',\n",
       "              'o',\n",
       "              'transientvoyager',\n",
       "              'of'): 0.43859949211194593,\n",
       "             ('kentucky',\n",
       "              'o',\n",
       "              'transientvoyager',\n",
       "              'of',\n",
       "              'heaven'): 0.43859949211194593,\n",
       "             ('o',\n",
       "              'transientvoyager',\n",
       "              'of',\n",
       "              'heaven',\n",
       "              '!'): 0.43859949211194593,\n",
       "             ('transientvoyager',\n",
       "              'of',\n",
       "              'heaven',\n",
       "              '!',\n",
       "              'o'): 0.43859949211194593,\n",
       "             ('of', 'heaven', '!', 'o', 'silent'): 0.43859949211194593,\n",
       "             ('heaven', '!', 'o', 'silent', 'sign'): 0.43859949211194593,\n",
       "             ('!', 'o', 'silent', 'sign', 'of'): 0.43859949211194593,\n",
       "             ('o', 'silent', 'sign', 'of', 'winter'): 0.43859949211194593,\n",
       "             ('silent', 'sign', 'of', 'winter', 'skies'): 0.43859949211194593,\n",
       "             ('sign', 'of', 'winter', 'skies', '!'): 0.43859949211194593,\n",
       "             ('of', 'winter', 'skies', '!', 'what'): 0.43859949211194593,\n",
       "             ('winter', 'skies', '!', 'what', 'adverse'): 0.43859949211194593,\n",
       "             ('skies', '!', 'what', 'adverse', 'wind'): 0.43859949211194593,\n",
       "             ('!', 'what', 'adverse', 'wind', 'thy'): 0.43859949211194593,\n",
       "             ('what', 'adverse', 'wind', 'thy', 'sail'): 0.43859949211194593,\n",
       "             ('adverse', 'wind', 'thy', 'sail', 'has'): 0.43859949211194593,\n",
       "             ('wind', 'thy', 'sail', 'has', 'driven'): 0.43859949211194593,\n",
       "             ('thy', 'sail', 'has', 'driven', 'to'): 0.43859949211194593,\n",
       "             ('sail', 'has', 'driven', 'to', 'dungeons'): 0.43859949211194593,\n",
       "             ('has', 'driven', 'to', 'dungeons', 'where'): 0.43859949211194593,\n",
       "             ('driven', 'to', 'dungeons', 'where', 'a'): 0.43859949211194593,\n",
       "             ('to', 'dungeons', 'where', 'a', 'prisoner'): 0.43859949211194593,\n",
       "             ('dungeons',\n",
       "              'where',\n",
       "              'a',\n",
       "              'prisoner',\n",
       "              'lies'): 0.43859949211194593,\n",
       "             ('where', 'a', 'prisoner', 'lies', '?'): 0.43859949211194593,\n",
       "             ('a', 'prisoner', 'lies', '?', 'methinks'): 0.43859949211194593,\n",
       "             ('prisoner', 'lies', '?', 'methinks', 'the'): 0.43859949211194593,\n",
       "             ('lies', '?', 'methinks', 'the', 'hands'): 0.43859949211194593,\n",
       "             ('?', 'methinks', 'the', 'hands', 'that'): 0.43859949211194593,\n",
       "             ('methinks', 'the', 'hands', 'that', 'shut'): 0.43859949211194593,\n",
       "             ('the', 'hands', 'that', 'shut', 'the'): 0.43859949211194593,\n",
       "             ('hands', 'that', 'shut', 'the', 'sun'): 0.43859949211194593,\n",
       "             ('that', 'shut', 'the', 'sun', 'so'): 0.43859949211194593,\n",
       "             ('shut', 'the', 'sun', 'so', 'sternly'): 0.43859949211194593,\n",
       "             ('the', 'sun', 'so', 'sternly', 'from'): 0.43859949211194593,\n",
       "             ('sun', 'so', 'sternly', 'from', 'this'): 0.43859949211194593,\n",
       "             ('so', 'sternly', 'from', 'this', 'morning'): 0.43859949211194593,\n",
       "             ('sternly', 'from', 'this', 'morning', \"'s\"): 0.43859949211194593,\n",
       "             ('from', 'this', 'morning', \"'s\", 'brow'): 0.43859949211194593,\n",
       "             ('this', 'morning', \"'s\", 'brow', 'might'): 0.43859949211194593,\n",
       "             ('morning', \"'s\", 'brow', 'might', 'still'): 0.43859949211194593,\n",
       "             (\"'s\", 'brow', 'might', 'still', 'their'): 0.43859949211194593,\n",
       "             ('brow', 'might', 'still', 'their', 'rebel'): 0.43859949211194593,\n",
       "             ('might', 'still', 'their', 'rebel', 'task'): 0.43859949211194593,\n",
       "             ('still', 'their', 'rebel', 'task', 'have'): 0.43859949211194593,\n",
       "             ('their', 'rebel', 'task', 'have', 'done'): 0.43859949211194593,\n",
       "             ('rebel', 'task', 'have', 'done', 'and'): 0.43859949211194593,\n",
       "             ('task', 'have', 'done', 'and', 'checked'): 0.43859949211194593,\n",
       "             ('have', 'done', 'and', 'checked', 'a'): 0.43859949211194593,\n",
       "             ('done', 'and', 'checked', 'a', 'thing'): 0.43859949211194593,\n",
       "             ('and', 'checked', 'a', 'thing', 'so'): 0.43859949211194593,\n",
       "             ('checked', 'a', 'thing', 'so', 'frail'): 0.43859949211194593,\n",
       "             ('a', 'thing', 'so', 'frail', 'as'): 0.43859949211194593,\n",
       "             ('thing', 'so', 'frail', 'as', 'thou'): 0.43859949211194593,\n",
       "             ('so', 'frail', 'as', 'thou', '.'): 0.43859949211194593,\n",
       "             ('frail', 'as', 'thou', '.', 'they'): 0.43859949211194593,\n",
       "             ('as', 'thou', '.', 'they', 'would'): 0.43859949211194593,\n",
       "             ('thou', '.', 'they', 'would', 'have'): 0.43859949211194593,\n",
       "             ('.', 'they', 'would', 'have', 'done'): 0.30488135779245923,\n",
       "             ('they', 'would', 'have', 'done', 'it'): 0.43859949211194593,\n",
       "             ('would', 'have', 'done', 'it', 'had'): 0.23364789499139027,\n",
       "             ('have', 'done', 'it', 'had', 'they'): 0.43859949211194593,\n",
       "             ('done', 'it', 'had', 'they', 'known'): 0.43859949211194593,\n",
       "             ('it', 'had', 'they', 'known', 'the'): 0.43859949211194593,\n",
       "             ('had', 'they', 'known', 'the', 'talisman'): 0.43859949211194593,\n",
       "             ('they', 'known', 'the', 'talisman', 'that'): 0.43859949211194593,\n",
       "             ('known',\n",
       "              'the',\n",
       "              'talisman',\n",
       "              'that',\n",
       "              'dwelt'): 0.43859949211194593,\n",
       "             ('the', 'talisman', 'that', 'dwelt', 'in'): 0.43859949211194593,\n",
       "             ('talisman', 'that', 'dwelt', 'in', 'thee'): 0.43859949211194593,\n",
       "             ('that', 'dwelt', 'in', 'thee', ','): 0.43859949211194593,\n",
       "             ('dwelt', 'in', 'thee', ',', 'for'): 0.43859949211194593,\n",
       "             ('in', 'thee', ',', 'for', 'all'): 0.23364789499139027,\n",
       "             ('thee', ',', 'for', 'all', 'the'): 0.43859949211194593,\n",
       "             (',', 'for', 'all', 'the', 'suns'): 0.06142617673308957,\n",
       "             ('for', 'all', 'the', 'suns', 'that'): 0.43859949211194593,\n",
       "             ('all', 'the', 'suns', 'that', 'ever'): 0.43859949211194593,\n",
       "             ('the', 'suns', 'that', 'ever', 'shone'): 0.43859949211194593,\n",
       "             ('suns', 'that', 'ever', 'shone', 'have'): 0.43859949211194593,\n",
       "             ('that', 'ever', 'shone', 'have', 'never'): 0.43859949211194593,\n",
       "             ('ever', 'shone', 'have', 'never', 'been'): 0.43859949211194593,\n",
       "             ('shone', 'have', 'never', 'been', 'so'): 0.43859949211194593,\n",
       "             ('have', 'never', 'been', 'so', 'kind'): 0.23364789499139027,\n",
       "             ('never', 'been', 'so', 'kind', 'to'): 0.43859949211194593,\n",
       "             ('been', 'so', 'kind', 'to', 'me'): 0.43859949211194593,\n",
       "             ('so', 'kind', 'to', 'me', '!'): 0.43859949211194593,\n",
       "             ('kind', 'to', 'me', '!', 'for'): 0.30488135779245923,\n",
       "             ('to', 'me', '!', 'for', 'many'): 0.43859949211194593,\n",
       "             ('me', '!', 'for', 'many', 'a'): 0.43859949211194593,\n",
       "             ('!', 'for', 'many', 'a', 'week'): 0.43859949211194593,\n",
       "             ('for', 'many', 'a', 'week', ','): 0.43859949211194593,\n",
       "             ('many', 'a', 'week', ',', 'and'): 0.43859949211194593,\n",
       "             ('a', 'week', ',', 'and', 'many'): 0.1893966511553912,\n",
       "             ('week', ',', 'and', 'many', 'a'): 0.43859949211194593,\n",
       "             (',', 'and', 'many', 'a', 'day'): 0.06142617673308957,\n",
       "             ('and', 'many', 'a', 'day', 'my'): 0.23364789499139027,\n",
       "             ('many', 'a', 'day', 'my', 'heart'): 0.43859949211194593,\n",
       "             ('a', 'day', 'my', 'heart', 'was'): 0.43859949211194593,\n",
       "             ('day', 'my', 'heart', 'was', 'weighed'): 0.43859949211194593,\n",
       "             ('my', 'heart', 'was', 'weighed', 'with'): 0.43859949211194593,\n",
       "             ('heart',\n",
       "              'was',\n",
       "              'weighed',\n",
       "              'with',\n",
       "              'sinking'): 0.43859949211194593,\n",
       "             ('was',\n",
       "              'weighed',\n",
       "              'with',\n",
       "              'sinking',\n",
       "              'gloom'): 0.43859949211194593,\n",
       "             ('weighed',\n",
       "              'with',\n",
       "              'sinking',\n",
       "              'gloom',\n",
       "              'when'): 0.43859949211194593,\n",
       "             ('with',\n",
       "              'sinking',\n",
       "              'gloom',\n",
       "              'when',\n",
       "              'morning'): 0.43859949211194593,\n",
       "             ('sinking',\n",
       "              'gloom',\n",
       "              'when',\n",
       "              'morning',\n",
       "              'rose'): 0.43859949211194593,\n",
       "             ('gloom', 'when', 'morning', 'rose', 'in'): 0.43859949211194593,\n",
       "             ('when',\n",
       "              'morning',\n",
       "              'rose',\n",
       "              'in',\n",
       "              'mourning'): 0.43859949211194593,\n",
       "             ('morning',\n",
       "              'rose',\n",
       "              'in',\n",
       "              'mourning',\n",
       "              'grey'): 0.43859949211194593,\n",
       "             ('rose', 'in', 'mourning', 'grey', 'and'): 0.43859949211194593,\n",
       "             ('in', 'mourning', 'grey', 'and', 'faintly'): 0.43859949211194593,\n",
       "             ('mourning',\n",
       "              'grey',\n",
       "              'and',\n",
       "              'faintly',\n",
       "              'lit'): 0.43859949211194593,\n",
       "             ('grey', 'and', 'faintly', 'lit', 'my'): 0.43859949211194593,\n",
       "             ('and', 'faintly', 'lit', 'my', 'prison'): 0.43859949211194593,\n",
       "             ('faintly', 'lit', 'my', 'prison', 'room'): 0.43859949211194593,\n",
       "             ('lit', 'my', 'prison', 'room', 'but'): 0.43859949211194593,\n",
       "             ('my', 'prison', 'room', 'but', 'angel'): 0.43859949211194593,\n",
       "             ('prison', 'room', 'but', 'angel', 'like'): 0.43859949211194593,\n",
       "             ('room', 'but', 'angel', 'like', ','): 0.43859949211194593,\n",
       "             ('but', 'angel', 'like', ',', 'when'): 0.43859949211194593,\n",
       "             ('angel', 'like', ',', 'when', 'i'): 0.43859949211194593,\n",
       "             ('like', ',', 'when', 'i', 'awoke'): 0.30488135779245923,\n",
       "             (',', 'when', 'i', 'awoke', ','): 0.43859949211194593,\n",
       "             ('when', 'i', 'awoke', ',', 'thy'): 0.1893966511553912,\n",
       "             ('i', 'awoke', ',', 'thy', 'silvery'): 0.43859949211194593,\n",
       "             ('awoke', ',', 'thy', 'silvery', 'form'): 0.43859949211194593,\n",
       "             (',', 'thy', 'silvery', 'form', ','): 0.43859949211194593,\n",
       "             ('thy', 'silvery', 'form', ',', 'so'): 0.43859949211194593,\n",
       "             ('silvery', 'form', ',', 'so', 'soft'): 0.43859949211194593,\n",
       "             ('form', ',', 'so', 'soft', 'and'): 0.43859949211194593,\n",
       "             (',', 'so', 'soft', 'and', 'fair'): 0.43859949211194593,\n",
       "             ('so', 'soft', 'and', 'fair', 'shining'): 0.43859949211194593,\n",
       "             ('soft',\n",
       "              'and',\n",
       "              'fair',\n",
       "              'shining',\n",
       "              'through'): 0.43859949211194593,\n",
       "             ('and',\n",
       "              'fair',\n",
       "              'shining',\n",
       "              'through',\n",
       "              'darkness'): 0.43859949211194593,\n",
       "             ('fair',\n",
       "              'shining',\n",
       "              'through',\n",
       "              'darkness',\n",
       "              ','): 0.43859949211194593,\n",
       "             ('shining',\n",
       "              'through',\n",
       "              'darkness',\n",
       "              ',',\n",
       "              'sweetly'): 0.43859949211194593,\n",
       "             ('through',\n",
       "              'darkness',\n",
       "              ',',\n",
       "              'sweetly',\n",
       "              'spoke'): 0.43859949211194593,\n",
       "             ('darkness', ',', 'sweetly', 'spoke', 'of'): 0.43859949211194593,\n",
       "             (',', 'sweetly', 'spoke', 'of', 'cloudy'): 0.43859949211194593,\n",
       "             ('sweetly',\n",
       "              'spoke',\n",
       "              'of',\n",
       "              'cloudy',\n",
       "              'skies'): 0.43859949211194593,\n",
       "             ('spoke', 'of', 'cloudy', 'skies', 'and'): 0.43859949211194593,\n",
       "             ('of',\n",
       "              'cloudy',\n",
       "              'skies',\n",
       "              'and',\n",
       "              'mountains'): 0.43859949211194593,\n",
       "             ('cloudy',\n",
       "              'skies',\n",
       "              'and',\n",
       "              'mountains',\n",
       "              'bare'): 0.43859949211194593,\n",
       "             ('skies', 'and', 'mountains', 'bare', ';'): 0.43859949211194593,\n",
       "             ('and', 'mountains', 'bare', ';', 'the'): 0.43859949211194593,\n",
       "             ('mountains', 'bare', ';', 'the', 'dearest'): 0.43859949211194593,\n",
       "             ('bare', ';', 'the', 'dearest', 'to'): 0.43859949211194593,\n",
       "             (';', 'the', 'dearest', 'to', 'a'): 0.43859949211194593,\n",
       "             ('the', 'dearest', 'to', 'a', 'mountaineer'): 0.43859949211194593,\n",
       "             ('dearest', 'to', 'a', 'mountaineer', 'who'): 0.43859949211194593,\n",
       "             ('to', 'a', 'mountaineer', 'who', ','): 0.43859949211194593,\n",
       "             ('a', 'mountaineer', 'who', ',', 'all'): 0.43859949211194593,\n",
       "             ('mountaineer', 'who', ',', 'all', 'life'): 0.43859949211194593,\n",
       "             ('who', ',', 'all', 'life', 'long'): 0.43859949211194593,\n",
       "             (',', 'all', 'life', 'long', 'has'): 0.43859949211194593,\n",
       "             ('all', 'life', 'long', 'has', 'loved'): 0.43859949211194593,\n",
       "             ('life', 'long', 'has', 'loved', 'the'): 0.43859949211194593,\n",
       "             ('long', 'has', 'loved', 'the', 'snow'): 0.43859949211194593,\n",
       "             ('has', 'loved', 'the', 'snow', 'that'): 0.43859949211194593,\n",
       "             ('loved', 'the', 'snow', 'that', 'crowned'): 0.43859949211194593,\n",
       "             ('the', 'snow', 'that', 'crowned', 'his'): 0.43859949211194593,\n",
       "             ('snow', 'that', 'crowned', 'his', 'native'): 0.43859949211194593,\n",
       "             ('that',\n",
       "              'crowned',\n",
       "              'his',\n",
       "              'native',\n",
       "              'summits'): 0.43859949211194593,\n",
       "             ('crowned',\n",
       "              'his',\n",
       "              'native',\n",
       "              'summits',\n",
       "              'drear'): 0.43859949211194593,\n",
       "             ('his', 'native', 'summits', 'drear', ','): 0.43859949211194593,\n",
       "             ('native',\n",
       "              'summits',\n",
       "              'drear',\n",
       "              ',',\n",
       "              'better'): 0.43859949211194593,\n",
       "             ('summits', 'drear', ',', 'better', ','): 0.43859949211194593,\n",
       "             ('drear', ',', 'better', ',', 'than'): 0.43859949211194593,\n",
       "             (',', 'better', ',', 'than', 'greenest'): 0.43859949211194593,\n",
       "             ('better',\n",
       "              ',',\n",
       "              'than',\n",
       "              'greenest',\n",
       "              'plains'): 0.43859949211194593,\n",
       "             (',', 'than', 'greenest', 'plains', 'below'): 0.43859949211194593,\n",
       "             ('than', 'greenest', 'plains', 'below', '.'): 0.43859949211194593,\n",
       "             ('greenest', 'plains', 'below', '.', 'and'): 0.43859949211194593,\n",
       "             ('plains', 'below', '.', 'and', 'voiceless'): 0.43859949211194593,\n",
       "             ('below', '.', 'and', 'voiceless', ','): 0.43859949211194593,\n",
       "             ('.', 'and', 'voiceless', ',', 'soulless'): 0.43859949211194593,\n",
       "             ('and', 'voiceless', ',', 'soulless', ','): 0.43859949211194593,\n",
       "             ('voiceless',\n",
       "              ',',\n",
       "              'soulless',\n",
       "              ',',\n",
       "              'messenger'): 0.43859949211194593,\n",
       "             (',', 'soulless', ',', 'messenger', 'thy'): 0.43859949211194593,\n",
       "             ('soulless',\n",
       "              ',',\n",
       "              'messenger',\n",
       "              'thy',\n",
       "              'presence'): 0.43859949211194593,\n",
       "             (',',\n",
       "              'messenger',\n",
       "              'thy',\n",
       "              'presence',\n",
       "              'waked'): 0.43859949211194593,\n",
       "             ('messenger',\n",
       "              'thy',\n",
       "              'presence',\n",
       "              'waked',\n",
       "              'a'): 0.43859949211194593,\n",
       "             ('thy',\n",
       "              'presence',\n",
       "              'waked',\n",
       "              'a',\n",
       "              'thrilling'): 0.43859949211194593,\n",
       "             ('presence',\n",
       "              'waked',\n",
       "              'a',\n",
       "              'thrilling',\n",
       "              'tone'): 0.43859949211194593,\n",
       "             ('waked', 'a', 'thrilling', 'tone', 'that'): 0.43859949211194593,\n",
       "             ('a',\n",
       "              'thrilling',\n",
       "              'tone',\n",
       "              'that',\n",
       "              'comforts'): 0.43859949211194593,\n",
       "             ('thrilling',\n",
       "              'tone',\n",
       "              'that',\n",
       "              'comforts',\n",
       "              'me'): 0.43859949211194593,\n",
       "             ('tone', 'that', 'comforts', 'me', 'while'): 0.43859949211194593,\n",
       "             ('that', 'comforts', 'me', 'while', 'thou'): 0.43859949211194593,\n",
       "             ('comforts', 'me', 'while', 'thou', 'art'): 0.43859949211194593,\n",
       "             ('me', 'while', 'thou', 'art', 'here'): 0.43859949211194593,\n",
       "             ('while', 'thou', 'art', 'here', 'and'): 0.43859949211194593,\n",
       "             ('thou', 'art', 'here', 'and', 'will'): 0.43859949211194593,\n",
       "             ('art', 'here', 'and', 'will', 'sustain'): 0.43859949211194593,\n",
       "             ('here', 'and', 'will', 'sustain', 'when'): 0.43859949211194593,\n",
       "             ('and', 'will', 'sustain', 'when', 'thou'): 0.43859949211194593,\n",
       "             ('will', 'sustain', 'when', 'thou', 'art'): 0.43859949211194593,\n",
       "             ('sustain', 'when', 'thou', 'art', 'gone'): 0.43859949211194593,\n",
       "             ('when', 'thou', 'art', 'gone', 'a'): 0.23364789499139027,\n",
       "             ('thou', 'art', 'gone', 'a', 'cento'): 0.43859949211194593,\n",
       "             ('art', 'gone', 'a', 'cento', 'for'): 0.43859949211194593,\n",
       "             ('gone', 'a', 'cento', 'for', 'sarah'): 0.43859949211194593,\n",
       "             ('a', 'cento', 'for', 'sarah', 'hegazy'): 0.467291117118338,\n",
       "             ('cento', 'for', 'sarah', 'hegazy', 'a'): 0.6097566180797127,\n",
       "             ('for', 'sarah', 'hegazy', 'a', 'cento'): 0.6097566180797127,\n",
       "             ('sarah', 'hegazy', 'a', 'cento', 'for'): 0.6097566180797127,\n",
       "             ('hegazy', 'a', 'cento', 'for', 'sarah'): 0.6097566180797127,\n",
       "             ('a', 'cento', 'for', 'sarah', 'hegazyin'): 0.2336473490901954,\n",
       "             ('cento', 'for', 'sarah', 'hegazyin', 'the'): 0.43859949211194593,\n",
       "             ('for',\n",
       "              'sarah',\n",
       "              'hegazyin',\n",
       "              'the',\n",
       "              'hiding'): 0.43859949211194593,\n",
       "             ('sarah',\n",
       "              'hegazyin',\n",
       "              'the',\n",
       "              'hiding',\n",
       "              'hour'): 0.43859949211194593,\n",
       "             ('hegazyin', 'the', 'hiding', 'hour', 'of'): 0.43859949211194593,\n",
       "             ('the', 'hiding', 'hour', 'of', 'autophagy'): 0.43859949211194593,\n",
       "             ('hiding',\n",
       "              'hour',\n",
       "              'of',\n",
       "              'autophagy',\n",
       "              'ghosts'): 0.43859949211194593,\n",
       "             ('hour',\n",
       "              'of',\n",
       "              'autophagy',\n",
       "              'ghosts',\n",
       "              'hang'): 0.43859949211194593,\n",
       "             ('of', 'autophagy', 'ghosts', 'hang', 'out'): 0.43859949211194593,\n",
       "             ('autophagy',\n",
       "              'ghosts',\n",
       "              'hang',\n",
       "              'out',\n",
       "              'all'): 0.43859949211194593,\n",
       "             ('ghosts', 'hang', 'out', 'all', 'day'): 0.43859949211194593,\n",
       "             ('hang', 'out', 'all', 'day', 'and'): 0.43859949211194593,\n",
       "             ('out', 'all', 'day', 'and', 'talk'): 0.43859949211194593,\n",
       "             ('all', 'day', 'and', 'talk', 'to'): 0.43859949211194593,\n",
       "             ('day', 'and', 'talk', 'to', 'us'): 0.43859949211194593,\n",
       "             ('and', 'talk', 'to', 'us', '.'): 0.43859949211194593,\n",
       "             ('talk', 'to', 'us', '.', 'an'): 0.43859949211194593,\n",
       "             ('to', 'us', '.', 'an', 'archival'): 0.43859949211194593,\n",
       "             ('us', '.', 'an', 'archival', 'haunting'): 0.43859949211194593,\n",
       "             ('.',\n",
       "              'an',\n",
       "              'archival',\n",
       "              'haunting',\n",
       "              'demanding'): 0.43859949211194593,\n",
       "             ('an',\n",
       "              'archival',\n",
       "              'haunting',\n",
       "              'demanding',\n",
       "              'tribute'): 0.43859949211194593,\n",
       "             ('archival',\n",
       "              'haunting',\n",
       "              'demanding',\n",
       "              'tribute',\n",
       "              'half'): 0.43859949211194593,\n",
       "             ('haunting',\n",
       "              'demanding',\n",
       "              'tribute',\n",
       "              'half',\n",
       "              'a'): 0.43859949211194593,\n",
       "             ('demanding',\n",
       "              'tribute',\n",
       "              'half',\n",
       "              'a',\n",
       "              'lime'): 0.43859949211194593,\n",
       "             ('tribute', 'half', 'a', 'lime', 'for'): 0.43859949211194593,\n",
       "             ('half', 'a', 'lime', 'for', 'breakfast'): 0.43859949211194593,\n",
       "             ('a', 'lime', 'for', 'breakfast', 'every'): 0.43859949211194593,\n",
       "             ('lime', 'for', 'breakfast', 'every', 'day'): 0.43859949211194593,\n",
       "             ('for', 'breakfast', 'every', 'day', '.'): 0.43859949211194593,\n",
       "             ('breakfast', 'every', 'day', '.', 'human'): 0.43859949211194593,\n",
       "             ('every', 'day', '.', 'human', 'voices'): 0.43859949211194593,\n",
       "             ('day', '.', 'human', 'voices', 'keening'): 0.43859949211194593,\n",
       "             ('.', 'human', 'voices', 'keening', 'in'): 0.43859949211194593,\n",
       "             ('human', 'voices', 'keening', 'in', 'pain'): 0.43859949211194593,\n",
       "             ('voices', 'keening', 'in', 'pain', 'their'): 0.43859949211194593,\n",
       "             ('keening', 'in', 'pain', 'their', 'bodies'): 0.43859949211194593,\n",
       "             ('in', 'pain', 'their', 'bodies', ','): 0.43859949211194593,\n",
       "             ('pain', 'their', 'bodies', ',', 'consumed'): 0.43859949211194593,\n",
       "             ('their', 'bodies', ',', 'consumed', 'by'): 0.43859949211194593,\n",
       "             ('bodies', ',', 'consumed', 'by', 'fire'): 0.43859949211194593,\n",
       "             (',', 'consumed', 'by', 'fire', 'light'): 0.43859949211194593,\n",
       "             ('consumed', 'by', 'fire', 'light', 'up'): 0.43859949211194593,\n",
       "             ('by', 'fire', 'light', 'up', 'the'): 0.43859949211194593,\n",
       "             ('fire', 'light', 'up', 'the', 'dark'): 0.43859949211194593,\n",
       "             ('light', 'up', 'the', 'dark', '.'): 0.43859949211194593,\n",
       "             ('up', 'the', 'dark', '.', 'they'): 0.43859949211194593,\n",
       "             ('the', 'dark', '.', 'they', 'will'): 0.43859949211194593,\n",
       "             ('dark', '.', 'they', 'will', 'blame'): 0.43859949211194593,\n",
       "             ('.', 'they', 'will', 'blame', 'the'): 0.43859949211194593,\n",
       "             ('they', 'will', 'blame', 'the', 'early'): 0.43859949211194593,\n",
       "             ('will', 'blame', 'the', 'early', 'morning'): 0.43859949211194593,\n",
       "             ('blame',\n",
       "              'the',\n",
       "              'early',\n",
       "              'morning',\n",
       "              'hours'): 0.43859949211194593,\n",
       "             ('the',\n",
       "              'early',\n",
       "              'morning',\n",
       "              'hours',\n",
       "              'under'): 0.43859949211194593,\n",
       "             ('early',\n",
       "              'morning',\n",
       "              'hours',\n",
       "              'under',\n",
       "              'the'): 0.43859949211194593,\n",
       "             ('morning', 'hours', 'under', 'the', 'seal'): 0.43859949211194593,\n",
       "             ('hours', 'under', 'the', 'seal', 'of'): 0.43859949211194593,\n",
       "             ('under', 'the', 'seal', 'of', 'secrecy'): 0.43859949211194593,\n",
       "             ('the', 'seal', 'of', 'secrecy', 'where'): 0.43859949211194593,\n",
       "             ('seal', 'of', 'secrecy', 'where', 'there'): 0.43859949211194593,\n",
       "             ('of', 'secrecy', 'where', 'there', 'was'): 0.43859949211194593,\n",
       "             ('secrecy', 'where', 'there', 'was', 'no'): 0.43859949211194593,\n",
       "             ('where', 'there', 'was', 'no', 'sunrise'): 0.30488135779245923,\n",
       "             ('there', 'was', 'no', 'sunrise', 'though'): 0.43859949211194593,\n",
       "             ('was', 'no', 'sunrise', 'though', 'moon'): 0.43859949211194593,\n",
       "             ('no', 'sunrise', 'though', 'moon', 'tells'): 0.43859949211194593,\n",
       "             ('sunrise', 'though', 'moon', 'tells', 'me'): 0.43859949211194593,\n",
       "             ('though', 'moon', 'tells', 'me', 'god'): 0.43859949211194593,\n",
       "             ('moon', 'tells', 'me', 'god', 'is'): 0.43859949211194593,\n",
       "             ('tells', 'me', 'god', 'is', 'love'): 0.43859949211194593,\n",
       "             ('me', 'god', 'is', 'love', 'unconditional'): 0.43859949211194593,\n",
       "             ('god', 'is', 'love', 'unconditional', '.'): 0.43859949211194593,\n",
       "             ('is', 'love', 'unconditional', '.', 'i'): 0.43859949211194593,\n",
       "             ('love', 'unconditional', '.', 'i', 'ten'): 0.43859949211194593,\n",
       "             ('unconditional',\n",
       "              '.',\n",
       "              'i',\n",
       "              'ten',\n",
       "              'thousand'): 0.43859949211194593,\n",
       "             ('.', 'i', 'ten', 'thousand', 'years'): 0.43859949211194593,\n",
       "             ('i', 'ten', 'thousand', 'years', 'old'): 0.43859949211194593,\n",
       "             ('ten', 'thousand', 'years', 'old', 'and'): 0.43859949211194593,\n",
       "             ('thousand', 'years', 'old', 'and', 'no'): 0.43859949211194593,\n",
       "             ('years', 'old', 'and', 'no', 'wind'): 0.43859949211194593,\n",
       "             ('old', 'and', 'no', 'wind', 'milk'): 0.43859949211194593,\n",
       "             ('and', 'no', 'wind', 'milk', 'souring'): 0.43859949211194593,\n",
       "             ('no', 'wind', 'milk', 'souring', 'on'): 0.43859949211194593,\n",
       "             ('wind', 'milk', 'souring', 'on', 'my'): 0.43859949211194593,\n",
       "             ('milk', 'souring', 'on', 'my', 'tongue'): 0.43859949211194593,\n",
       "             ('souring', 'on', 'my', 'tongue', 'whisper'): 0.43859949211194593,\n",
       "             ('on', 'my', 'tongue', 'whisper', 'until'): 0.43859949211194593,\n",
       "             ('my', 'tongue', 'whisper', 'until', 'we'): 0.43859949211194593,\n",
       "             ('tongue',\n",
       "              'whisper',\n",
       "              'until',\n",
       "              'we',\n",
       "              'sleep'): 0.43859949211194593,\n",
       "             ('whisper', 'until', 'we', 'sleep', 'do'): 0.43859949211194593,\n",
       "             ('until', 'we', 'sleep', 'do', 'you'): 0.43859949211194593,\n",
       "             ('we', 'sleep', 'do', 'you', 'see'): 0.43859949211194593,\n",
       "             ('sleep', 'do', 'you', 'see', 'the'): 0.43859949211194593,\n",
       "             ('do', 'you', 'see', 'the', 'map'): 0.1893966511553912,\n",
       "             ('you', 'see', 'the', 'map', 'home'): 0.43859949211194593,\n",
       "             ('see', 'the', 'map', 'home', '?'): 0.43859949211194593,\n",
       "             ('the', 'map', 'home', '?', 'this'): 0.43859949211194593,\n",
       "             ('map', 'home', '?', 'this', 'world'): 0.43859949211194593,\n",
       "             ('home', '?', 'this', 'world', 'will'): 0.43859949211194593,\n",
       "             ('?', 'this', 'world', 'will', 'have'): 0.43859949211194593,\n",
       "             ('this', 'world', 'will', 'have', 'you'): 0.43859949211194593,\n",
       "             ('world', 'will', 'have', 'you', 'running'): 0.43859949211194593,\n",
       "             ('will', 'have', 'you', 'running', 'to'): 0.43859949211194593,\n",
       "             ('have', 'you', 'running', 'to', 'stone'): 0.43859949211194593,\n",
       "             ('you', 'running', 'to', 'stone', 'for'): 0.43859949211194593,\n",
       "             ('running', 'to', 'stone', 'for', 'embrace'): 0.43859949211194593,\n",
       "             ('to',\n",
       "              'stone',\n",
       "              'for',\n",
       "              'embrace',\n",
       "              'gravestone'): 0.43859949211194593,\n",
       "             ('stone',\n",
       "              'for',\n",
       "              'embrace',\n",
       "              'gravestone',\n",
       "              'gentler'): 0.43859949211194593,\n",
       "             ('for',\n",
       "              'embrace',\n",
       "              'gravestone',\n",
       "              'gentler',\n",
       "              'than'): 0.43859949211194593,\n",
       "             ('embrace',\n",
       "              'gravestone',\n",
       "              'gentler',\n",
       "              'than',\n",
       "              'human'): 0.43859949211194593,\n",
       "             ('gravestone',\n",
       "              'gentler',\n",
       "              'than',\n",
       "              'human',\n",
       "              '.'): 0.43859949211194593,\n",
       "             ('gentler', 'than', 'human', '.', 'the'): 0.43859949211194593,\n",
       "             ('than', 'human', '.', 'the', 'wretched'): 0.43859949211194593,\n",
       "             ('human', '.', 'the', 'wretched', 'left'): 0.43859949211194593,\n",
       "             ('.', 'the', 'wretched', 'left', 'a'): 0.43859949211194593,\n",
       "             ('the', 'wretched', 'left', 'a', 'monument'): 0.43859949211194593,\n",
       "             ('wretched', 'left', 'a', 'monument', 'of'): 0.43859949211194593,\n",
       "             ('left', 'a', 'monument', 'of', 'comments'): 0.43859949211194593,\n",
       "             ('a', 'monument', 'of', 'comments', 'that'): 0.43859949211194593,\n",
       "             ('monument',\n",
       "              'of',\n",
       "              'comments',\n",
       "              'that',\n",
       "              'day'): 0.43859949211194593,\n",
       "             ('of', 'comments', 'that', 'day', 'in'): 0.43859949211194593,\n",
       "             ('comments', 'that', 'day', 'in', 'the'): 0.43859949211194593,\n",
       "             ('that', 'day', 'in', 'the', 'place'): 0.23364789499139027,\n",
       "             ('day', 'in', 'the', 'place', 'of'): 0.43859949211194593,\n",
       "             ('in', 'the', 'place', 'of', 'thunder'): 0.12077492472853361,\n",
       "             ('the', 'place', 'of', 'thunder', ','): 0.43859949211194593,\n",
       "             ('place', 'of', 'thunder', ',', 'i'): 0.43859949211194593,\n",
       "             ('of', 'thunder', ',', 'i', 'have'): 0.43859949211194593,\n",
       "             ('thunder', ',', 'i', 'have', 'faith'): 0.43859949211194593,\n",
       "             (',', 'i', 'have', 'faith', 'in'): 0.43859949211194593,\n",
       "             ('i', 'have', 'faith', 'in', 'a'): 0.43859949211194593,\n",
       "             ('have', 'faith', 'in', 'a', 'world'): 0.43859949211194593,\n",
       "             ('faith', 'in', 'a', 'world', 'of'): 0.43859949211194593,\n",
       "             ('in', 'a', 'world', 'of', 'signs'): 0.07002926464440201,\n",
       "             ('a', 'world', 'of', 'signs', 'and'): 0.43859949211194593,\n",
       "             ('world', 'of', 'signs', 'and', 'wonder'): 0.43859949211194593,\n",
       "             ('of', 'signs', 'and', 'wonder', '.'): 0.43859949211194593,\n",
       "             ('signs', 'and', 'wonder', '.', 'this'): 0.43859949211194593,\n",
       "             ('and', 'wonder', '.', 'this', 'time'): 0.43859949211194593,\n",
       "             ('wonder', '.', 'this', 'time', 'it'): 0.43859949211194593,\n",
       "             ('.', 'this', 'time', 'it', 'will'): 0.30488135779245923,\n",
       "             ('this', 'time', 'it', 'will', 'be'): 0.43859949211194593,\n",
       "             ('time', 'it', 'will', 'be', 'different'): 0.43859949211194593,\n",
       "             ('it', 'will', 'be', 'different', 'arab'): 0.43859949211194593,\n",
       "             ('will',\n",
       "              'be',\n",
       "              'different',\n",
       "              'arab',\n",
       "              'spring'): 0.43859949211194593,\n",
       "             ('be',\n",
       "              'different',\n",
       "              'arab',\n",
       "              'spring',\n",
       "              'forcing'): 0.43859949211194593,\n",
       "             ('different',\n",
       "              'arab',\n",
       "              'spring',\n",
       "              'forcing',\n",
       "              'its'): 0.43859949211194593,\n",
       "             ('arab', 'spring', 'forcing', 'its', 'way'): 0.43859949211194593,\n",
       "             ('spring', 'forcing', 'its', 'way', 'old'): 0.43859949211194593,\n",
       "             ('forcing', 'its', 'way', 'old', 'life'): 0.43859949211194593,\n",
       "             ('its', 'way', 'old', 'life', 're-members'): 0.43859949211194593,\n",
       "             ('way',\n",
       "              'old',\n",
       "              'life',\n",
       "              're-members',\n",
       "              'lightening'): 0.43859949211194593,\n",
       "             ('old',\n",
       "              'life',\n",
       "              're-members',\n",
       "              'lightening',\n",
       "              'would'): 0.43859949211194593,\n",
       "             ('life',\n",
       "              're-members',\n",
       "              'lightening',\n",
       "              'would',\n",
       "              'manifest'): 0.43859949211194593,\n",
       "             ('re-members',\n",
       "              'lightening',\n",
       "              'would',\n",
       "              'manifest',\n",
       "              'from'): 0.43859949211194593,\n",
       "             ('lightening',\n",
       "              'would',\n",
       "              'manifest',\n",
       "              'from',\n",
       "              'the'): 0.43859949211194593,\n",
       "             ('would',\n",
       "              'manifest',\n",
       "              'from',\n",
       "              'the',\n",
       "              'stale'): 0.43859949211194593,\n",
       "             ('manifest', 'from', 'the', 'stale', 'air'): 0.43859949211194593,\n",
       "             ('from', 'the', 'stale', 'air', '.'): 0.43859949211194593,\n",
       "             ('the', 'stale', 'air', '.', 'you'): 0.43859949211194593,\n",
       "             ('stale', 'air', '.', 'you', 'are'): 0.43859949211194593,\n",
       "             ('air', '.', 'you', 'are', 'prepared'): 0.30488135779245923,\n",
       "             ('.', 'you', 'are', 'prepared', 'for'): 0.43859949211194593,\n",
       "             ('you', 'are', 'prepared', 'for', 'all'): 0.43859949211194593,\n",
       "             ('are', 'prepared', 'for', 'all', 'of'): 0.43859949211194593,\n",
       "             ('prepared', 'for', 'all', 'of', 'it'): 0.43859949211194593,\n",
       "             ('for', 'all', 'of', 'it', 'paraded'): 0.43859949211194593,\n",
       "             ('all',\n",
       "              'of',\n",
       "              'it',\n",
       "              'paraded',\n",
       "              'processions'): 0.43859949211194593,\n",
       "             ('of',\n",
       "              'it',\n",
       "              'paraded',\n",
       "              'processions',\n",
       "              'wedding'): 0.43859949211194593,\n",
       "             ('it',\n",
       "              'paraded',\n",
       "              'processions',\n",
       "              'wedding',\n",
       "              'ecstatic'): 0.43859949211194593,\n",
       "             ('paraded',\n",
       "              'processions',\n",
       "              'wedding',\n",
       "              'ecstatic',\n",
       "              'when'): 0.43859949211194593,\n",
       "             ('processions',\n",
       "              'wedding',\n",
       "              'ecstatic',\n",
       "              'when',\n",
       "              'the'): 0.43859949211194593,\n",
       "             ('wedding',\n",
       "              'ecstatic',\n",
       "              'when',\n",
       "              'the',\n",
       "              'fists'): 0.43859949211194593,\n",
       "             ('ecstatic', 'when', 'the', 'fists', 'rush'): 0.43859949211194593,\n",
       "             ('when', 'the', 'fists', 'rush', 'towards'): 0.43859949211194593,\n",
       "             ('the', 'fists', 'rush', 'towards', 'your'): 0.43859949211194593,\n",
       "             ('fists', 'rush', 'towards', 'your', 'gut'): 0.43859949211194593,\n",
       "             ('rush', 'towards', 'your', 'gut', 'they'): 0.43859949211194593,\n",
       "             ('towards', 'your', 'gut', 'they', 'will'): 0.43859949211194593,\n",
       "             ('your', 'gut', 'they', 'will', 'find'): 0.43859949211194593,\n",
       "             ('gut', 'they', 'will', 'find', 'instead'): 0.43859949211194593,\n",
       "             ('they', 'will', 'find', 'instead', 'smoke'): 0.43859949211194593,\n",
       "             ('will', 'find', 'instead', 'smoke', '.'): 0.43859949211194593,\n",
       "             ('find', 'instead', 'smoke', '.', 'our'): 0.43859949211194593,\n",
       "             ('instead', 'smoke', '.', 'our', 'desire'): 0.43859949211194593,\n",
       "             ('smoke', '.', 'our', 'desire', 'up'): 0.43859949211194593,\n",
       "             ('.', 'our', 'desire', 'up', 'to'): 0.43859949211194593,\n",
       "             ('our', 'desire', 'up', 'to', 'our'): 0.43859949211194593,\n",
       "             ('desire', 'up', 'to', 'our', 'throats'): 0.43859949211194593,\n",
       "             ('up', 'to', 'our', 'throats', ','): 0.43859949211194593,\n",
       "             ('to', 'our', 'throats', ',', 'increased'): 0.43859949211194593,\n",
       "             ('our',\n",
       "              'throats',\n",
       "              ',',\n",
       "              'increased',\n",
       "              'blood'): 0.43859949211194593,\n",
       "             ('throats',\n",
       "              ',',\n",
       "              'increased',\n",
       "              'blood',\n",
       "              'flow'): 0.43859949211194593,\n",
       "             (',',\n",
       "              'increased',\n",
       "              'blood',\n",
       "              'flow',\n",
       "              'ripping'): 0.43859949211194593,\n",
       "             ('increased',\n",
       "              'blood',\n",
       "              'flow',\n",
       "              'ripping',\n",
       "              'heart'): 0.43859949211194593,\n",
       "             ('blood',\n",
       "              'flow',\n",
       "              'ripping',\n",
       "              'heart',\n",
       "              'open'): 0.43859949211194593,\n",
       "             ('flow', 'ripping', 'heart', 'open', 'from'): 0.43859949211194593,\n",
       "             ('ripping',\n",
       "              'heart',\n",
       "              'open',\n",
       "              'from',\n",
       "              'within'): 0.43859949211194593,\n",
       "             ('heart', 'open', 'from', 'within', 'dead'): 0.43859949211194593,\n",
       "             ('open', 'from', 'within', 'dead', 'now'): 0.43859949211194593,\n",
       "             ('from', 'within', 'dead', 'now', 'after'): 0.43859949211194593,\n",
       "             ('within',\n",
       "              'dead',\n",
       "              'now',\n",
       "              'after',\n",
       "              'decimating'): 0.43859949211194593,\n",
       "             ('dead',\n",
       "              'now',\n",
       "              'after',\n",
       "              'decimating',\n",
       "              'perfectly'): 0.43859949211194593,\n",
       "             ('now',\n",
       "              'after',\n",
       "              'decimating',\n",
       "              'perfectly',\n",
       "              'healthy'): 0.43859949211194593,\n",
       "             ('after',\n",
       "              'decimating',\n",
       "              'perfectly',\n",
       "              'healthy',\n",
       "              'skin'): 0.43859949211194593,\n",
       "             ('decimating',\n",
       "              'perfectly',\n",
       "              'healthy',\n",
       "              'skin',\n",
       "              'we'): 0.43859949211194593,\n",
       "             ('perfectly',\n",
       "              'healthy',\n",
       "              'skin',\n",
       "              'we',\n",
       "              'will'): 0.43859949211194593,\n",
       "             ('healthy', 'skin', 'we', 'will', 'become'): 0.43859949211194593,\n",
       "             ('skin', 'we', 'will', 'become', 'history'): 0.43859949211194593,\n",
       "             ('we',\n",
       "              'will',\n",
       "              'become',\n",
       "              'history',\n",
       "              'contested'): 0.43859949211194593,\n",
       "             ('will',\n",
       "              'become',\n",
       "              'history',\n",
       "              'contested',\n",
       "              '.'): 0.43859949211194593,\n",
       "             ('become', 'history', 'contested', '.', 'a'): 0.43859949211194593,\n",
       "             ('history', 'contested', '.', 'a', 'light'): 0.43859949211194593,\n",
       "             ('contested', '.', 'a', 'light', 'in'): 0.43859949211194593,\n",
       "             ('.', 'a', 'light', 'in', 'the'): 0.30488135779245923,\n",
       "             ('a', 'light', 'in', 'the', 'earth'): 0.30488135779245923,\n",
       "             ('light', 'in', 'the', 'earth', 'of'): 0.43859949211194593,\n",
       "             ('in', 'the', 'earth', 'of', 'her'): 0.43859949211194593,\n",
       "             ('the', 'earth', 'of', 'her', 'chest'): 0.43859949211194593,\n",
       "             ('earth', 'of', 'her', 'chest', '.'): 0.43859949211194593,\n",
       "             ('of', 'her', 'chest', '.', 'grief'): 0.43859949211194593,\n",
       "             ('her', 'chest', '.', 'grief', 'is'): 0.43859949211194593,\n",
       "             ('chest', '.', 'grief', 'is', 'a'): 0.43859949211194593,\n",
       "             ('.', 'grief', 'is', 'a', 'country'): 0.30488135779245923,\n",
       "             ('grief', 'is', 'a', 'country', 'without'): 0.43859949211194593,\n",
       "             ('is', 'a', 'country', 'without', 'borders'): 0.43859949211194593,\n",
       "             ('a',\n",
       "              'country',\n",
       "              'without',\n",
       "              'borders',\n",
       "              'eulogy'): 0.43859949211194593,\n",
       "             ('country',\n",
       "              'without',\n",
       "              'borders',\n",
       "              'eulogy',\n",
       "              'to'): 0.43859949211194593,\n",
       "             ('without', 'borders', 'eulogy', 'to', 'be'): 0.43859949211194593,\n",
       "             ('borders', 'eulogy', 'to', 'be', 'read'): 0.43859949211194593,\n",
       "             ('eulogy', 'to', 'be', 'read', 'from'): 0.43859949211194593,\n",
       "             ('to', 'be', 'read', 'from', 'right'): 0.7575752410497666,\n",
       "             ('be', 'read', 'from', 'right', 'to'): 0.7575752410497666,\n",
       "             ('read', 'from', 'right', 'to', 'left'): 0.7575752410497666,\n",
       "             ('from', 'right', 'to', 'left', 'babas'): 0.1893966511553912,\n",
       "             ('right', 'to', 'left', 'babas', 'tongue'): 0.43859949211194593,\n",
       "             ('to', 'left', 'babas', 'tongue', 'buried'): 0.43859949211194593,\n",
       "             ('left', 'babas', 'tongue', 'buried', 'in'): 0.43859949211194593,\n",
       "             ('babas', 'tongue', 'buried', 'in', 'sand'): 0.43859949211194593,\n",
       "             ('tongue', 'buried', 'in', 'sand', 'i'): 0.43859949211194593,\n",
       "             ('buried', 'in', 'sand', 'i', 'dream'): 0.43859949211194593,\n",
       "             ('in', 'sand', 'i', 'dream', 'in'): 0.43859949211194593,\n",
       "             ('sand', 'i', 'dream', 'in', 'arabic'): 0.43859949211194593,\n",
       "             ('i', 'dream', 'in', 'arabic', 'of'): 0.43859949211194593,\n",
       "             ('dream', 'in', 'arabic', 'of', 'salt'): 0.43859949211194593,\n",
       "             ('in', 'arabic', 'of', 'salt', 'drink'): 0.43859949211194593,\n",
       "             ('arabic', 'of', 'salt', 'drink', 'gallons'): 0.43859949211194593,\n",
       "             ('of', 'salt', 'drink', 'gallons', 'but'): 0.43859949211194593,\n",
       "             ('salt', 'drink', 'gallons', 'but', 'the'): 0.43859949211194593,\n",
       "             ('drink', 'gallons', 'but', 'the', 'ocean'): 0.43859949211194593,\n",
       "             ('gallons', 'but', 'the', 'ocean', 'stays'): 0.43859949211194593,\n",
       "             ('but', 'the', 'ocean', 'stays', 'the'): 0.43859949211194593,\n",
       "             ('the', 'ocean', 'stays', 'the', 'ocean'): 0.43859949211194593,\n",
       "             ('ocean', 'stays', 'the', 'ocean', 'and'): 0.43859949211194593,\n",
       "             ('stays', 'the', 'ocean', 'and', 'once'): 0.43859949211194593,\n",
       "             ('the', 'ocean', 'and', 'once', 'again'): 0.43859949211194593,\n",
       "             ('ocean', 'and', 'once', 'again', 'i'): 0.43859949211194593,\n",
       "             ('and', 'once', 'again', 'i', 'wake'): 0.23364789499139027,\n",
       "             ('once', 'again', 'i', 'wake', 'am'): 0.43859949211194593,\n",
       "             ('again', 'i', 'wake', 'am', 'a'): 0.43859949211194593,\n",
       "             ('i', 'wake', 'am', 'a', 'wake'): 0.43859949211194593,\n",
       "             ('wake', 'am', 'a', 'wake', 'in'): 0.43859949211194593,\n",
       "             ('am', 'a', 'wake', 'in', 'english'): 0.43859949211194593,\n",
       "             ('a', 'wake', 'in', 'english', '.'): 0.43859949211194593,\n",
       "             ('wake', 'in', 'english', '.', 'im'): 0.43859949211194593,\n",
       "             ('in', 'english', '.', 'im', 'thirsty'): 0.43859949211194593,\n",
       "             ('english', '.', 'im', 'thirsty', 'is'): 0.43859949211194593,\n",
       "             ('.', 'im', 'thirsty', 'is', 'whats'): 0.43859949211194593,\n",
       "             ('im', 'thirsty', 'is', 'whats', 'killing'): 0.43859949211194593,\n",
       "             ('thirsty', 'is', 'whats', 'killing', 'me'): 0.43859949211194593,\n",
       "             ('is', 'whats', 'killing', 'me', 'most'): 0.43859949211194593,\n",
       "             ('whats', 'killing', 'me', 'most', '.'): 0.43859949211194593,\n",
       "             ('killing', 'me', 'most', '.', 'dont'): 0.43859949211194593,\n",
       "             ('me', 'most', '.', 'dont', 'die'): 0.43859949211194593,\n",
       "             ('most', '.', 'dont', 'die', 'this'): 0.43859949211194593,\n",
       "             ('.', 'dont', 'die', 'this', 'way'): 0.43859949211194593,\n",
       "             ('dont', 'die', 'this', 'way', '.'): 0.43859949211194593,\n",
       "             ('die', 'this', 'way', '.', 'wake'): 0.43859949211194593,\n",
       "             ('this', 'way', '.', 'wake', 'up'): 0.43859949211194593,\n",
       "             ('way', '.', 'wake', 'up', 'drink'): 0.43859949211194593,\n",
       "             ('.', 'wake', 'up', 'drink', 'water'): 0.43859949211194593,\n",
       "             ('wake', 'up', 'drink', 'water', 'one'): 0.43859949211194593,\n",
       "             ('up', 'drink', 'water', 'one', 'foot'): 0.43859949211194593,\n",
       "             ('drink', 'water', 'one', 'foot', 'and'): 0.43859949211194593,\n",
       "             ('water', 'one', 'foot', 'and', 'then'): 0.43859949211194593,\n",
       "             ('one', 'foot', 'and', 'then', 'the'): 0.43859949211194593,\n",
       "             ('foot', 'and', 'then', 'the', 'next'): 0.43859949211194593,\n",
       "             ('and', 'then', 'the', 'next', 'walk'): 0.30488135779245923,\n",
       "             ('then', 'the', 'next', 'walk', 'meet'): 0.43859949211194593,\n",
       "             ('the', 'next', 'walk', 'meet', 'the'): 0.43859949211194593,\n",
       "             ('next', 'walk', 'meet', 'the', 'sun'): 0.43859949211194593,\n",
       "             ('walk', 'meet', 'the', 'sun', 'a'): 0.43859949211194593,\n",
       "             ('meet', 'the', 'sun', 'a', 'face'): 0.43859949211194593,\n",
       "             ('the', 'sun', 'a', 'face', 'that'): 0.43859949211194593,\n",
       "             ('sun', 'a', 'face', 'that', 'is'): 0.43859949211194593,\n",
       "             ('a', 'face', 'that', 'is', 'so'): 0.43859949211194593,\n",
       "             ('face', 'that', 'is', 'so', 'itself'): 0.43859949211194593,\n",
       "             ('that', 'is', 'so', 'itself', 'to'): 0.43859949211194593,\n",
       "             ('is', 'so', 'itself', 'to', 'look'): 0.43859949211194593,\n",
       "             ('so', 'itself', 'to', 'look', 'upon'): 0.43859949211194593,\n",
       "             ('itself', 'to', 'look', 'upon', 'it'): 0.43859949211194593,\n",
       "             ('to', 'look', 'upon', 'it', 'on'): 0.43859949211194593,\n",
       "             ('look', 'upon', 'it', 'on', 'that'): 0.43859949211194593,\n",
       "             ('upon', 'it', 'on', 'that', 'summer'): 0.43859949211194593,\n",
       "             ('it', 'on', 'that', 'summer', 'day'): 0.43859949211194593,\n",
       "             ('on', 'that', 'summer', 'day', 'was'): 0.43859949211194593,\n",
       "             ('that', 'summer', 'day', 'was', 'like'): 0.43859949211194593,\n",
       "             ('summer', 'day', 'was', 'like', 'drinking'): 0.43859949211194593,\n",
       "             ('day', 'was', 'like', 'drinking', 'prism'): 0.43859949211194593,\n",
       "             ('was',\n",
       "              'like',\n",
       "              'drinking',\n",
       "              'prism',\n",
       "              'refracting'): 0.43859949211194593,\n",
       "             ('like',\n",
       "              'drinking',\n",
       "              'prism',\n",
       "              'refracting',\n",
       "              'rainbow'): 0.43859949211194593,\n",
       "             ('drinking',\n",
       "              'prism',\n",
       "              'refracting',\n",
       "              'rainbow',\n",
       "              'rupture'): 0.43859949211194593,\n",
       "             ('prism',\n",
       "              'refracting',\n",
       "              'rainbow',\n",
       "              'rupture',\n",
       "              'rapture'): 0.43859949211194593,\n",
       "             ('refracting',\n",
       "              'rainbow',\n",
       "              'rupture',\n",
       "              'rapture',\n",
       "              'who'): 0.43859949211194593,\n",
       "             ('rainbow',\n",
       "              'rupture',\n",
       "              'rapture',\n",
       "              'who',\n",
       "              'washed'): 0.43859949211194593,\n",
       "             ('rupture',\n",
       "              'rapture',\n",
       "              'who',\n",
       "              'washed',\n",
       "              'her'): 0.43859949211194593,\n",
       "             ('rapture', 'who', 'washed', 'her', ','): 0.43859949211194593,\n",
       "             ('who', 'washed', 'her', ',', 'who'): 0.43859949211194593,\n",
       "             ('washed', 'her', ',', 'who', 'folded'): 0.43859949211194593,\n",
       "             ('her', ',', 'who', 'folded', 'her'): 0.43859949211194593,\n",
       "             (',', 'who', 'folded', 'her', 'into'): 0.43859949211194593,\n",
       "             ('who', 'folded', 'her', 'into', 'eternity'): 0.43859949211194593,\n",
       "             ('folded', 'her', 'into', 'eternity', ','): 0.43859949211194593,\n",
       "             ('her', 'into', 'eternity', ',', 'who'): 0.43859949211194593,\n",
       "             ('into', 'eternity', ',', 'who', 'this'): 0.43859949211194593,\n",
       "             ('eternity', ',', 'who', 'this', 'is'): 0.43859949211194593,\n",
       "             (',', 'who', 'this', 'is', 'the'): 0.43859949211194593,\n",
       "             ('who', 'this', 'is', 'the', 'only'): 0.43859949211194593,\n",
       "             ('this', 'is', 'the', 'only', 'river'): 0.13736481855157193,\n",
       "             ('is', 'the', 'only', 'river', 'i'): 0.43859949211194593,\n",
       "             ('the', 'only', 'river', 'i', 'want'): 0.43859949211194593,\n",
       "             ('only', 'river', 'i', 'want', 'to'): 0.43859949211194593,\n",
       "             ('river', 'i', 'want', 'to', 'write'): 0.43859949211194593,\n",
       "             ('i', 'want', 'to', 'write', 'about'): 0.10776042749861801,\n",
       "             ('want', 'to', 'write', 'about', '.'): 0.15923809281165857,\n",
       "             ('to', 'write', 'about', '.', 'i'): 0.43859949211194593,\n",
       "             ('write', 'about', '.', 'i', 'am'): 0.43859949211194593,\n",
       "             ('about', '.', 'i', 'am', 'the'): 0.43859949211194593,\n",
       "             ('.', 'i', 'am', 'the', 'entire'): 0.016318856240768814,\n",
       "             ('i', 'am', 'the', 'entire', 'galaxy'): 0.43859949211194593,\n",
       "             ('am', 'the', 'entire', 'galaxy', 'in'): 0.43859949211194593,\n",
       "             ('the', 'entire', 'galaxy', 'in', 'a'): 0.43859949211194593,\n",
       "             ('entire', 'galaxy', 'in', 'a', 'drop'): 0.43859949211194593,\n",
       "             ('galaxy', 'in', 'a', 'drop', '.'): 0.43859949211194593,\n",
       "             ('in', 'a', 'drop', '.', 'dont'): 0.43859949211194593,\n",
       "             ('a', 'drop', '.', 'dont', 'you'): 0.43859949211194593,\n",
       "             ('drop', '.', 'dont', 'you', 'know'): 0.43859949211194593,\n",
       "             ('.', 'dont', 'you', 'know', 'i'): 0.43859949211194593,\n",
       "             ('dont', 'you', 'know', 'i', 'am'): 0.30488135779245923,\n",
       "             ('you', 'know', 'i', 'am', 'everything'): 0.1893966511553912,\n",
       "             ('know', 'i', 'am', 'everything', '?'): 0.43859949211194593,\n",
       "             ('i', 'am', 'everything', '?', 'an'): 0.43859949211194593,\n",
       "             ('am', 'everything', '?', 'an', 'absconded'): 0.43859949211194593,\n",
       "             ('everything',\n",
       "              '?',\n",
       "              'an',\n",
       "              'absconded',\n",
       "              'city'): 0.43859949211194593,\n",
       "             ('?', 'an', 'absconded', 'city', 'of'): 0.43859949211194593,\n",
       "             ('an', 'absconded', 'city', 'of', 'bees'): 0.43859949211194593,\n",
       "             ('absconded', 'city', 'of', 'bees', '.'): 0.43859949211194593,\n",
       "             ('city', 'of', 'bees', '.', 'a'): 0.43859949211194593,\n",
       "             ('of', 'bees', '.', 'a', 'novel'): 0.43859949211194593,\n",
       "             ('bees', '.', 'a', 'novel', 'adjective'): 0.43859949211194593,\n",
       "             ('.', 'a', 'novel', 'adjective', '.'): 0.43859949211194593,\n",
       "             ('a', 'novel', 'adjective', '.', 'each'): 0.43859949211194593,\n",
       "             ('novel',\n",
       "              'adjective',\n",
       "              '.',\n",
       "              'each',\n",
       "              'moment'): 0.43859949211194593,\n",
       "             ('adjective', '.', 'each', 'moment', 'i'): 0.43859949211194593,\n",
       "             ('.', 'each', 'moment', 'i', 'invoke'): 0.43859949211194593,\n",
       "             ('each', 'moment', 'i', 'invoke', 'the'): 0.43859949211194593,\n",
       "             ('moment', 'i', 'invoke', 'the', 'music'): 0.43859949211194593,\n",
       "             ('i', 'invoke', 'the', 'music', 'of'): 0.43859949211194593,\n",
       "             ('invoke', 'the', 'music', 'of', 'my'): 0.43859949211194593,\n",
       "             ('the', 'music', 'of', 'my', 'people'): 0.30488135779245923,\n",
       "             ('music', 'of', 'my', 'people', 'who'): 0.43859949211194593,\n",
       "             ('of', 'my', 'people', 'who', 'danced'): 0.30488135779245923,\n",
       "             ('my', 'people', 'who', 'danced', 'in'): 0.43859949211194593,\n",
       "             ('people', 'who', 'danced', 'in', 'a'): 0.43859949211194593,\n",
       "             ('who', 'danced', 'in', 'a', 'room'): 0.43859949211194593,\n",
       "             ('danced', 'in', 'a', 'room', 'so'): 0.43859949211194593,\n",
       "             ('in', 'a', 'room', 'so', 'small'): 0.43859949211194593,\n",
       "             ('a', 'room', 'so', 'small', 'our'): 0.43859949211194593,\n",
       "             ('room', 'so', 'small', 'our', 'knees'): 0.43859949211194593,\n",
       "             ('so', 'small', 'our', 'knees', 'kissed'): 0.43859949211194593,\n",
       "             ('small', 'our', 'knees', 'kissed', 'half'): 0.43859949211194593,\n",
       "             ('our',\n",
       "              'knees',\n",
       "              'kissed',\n",
       "              'half',\n",
       "              'laughing'): 0.43859949211194593,\n",
       "             ('knees',\n",
       "              'kissed',\n",
       "              'half',\n",
       "              'laughing',\n",
       "              'half'): 0.43859949211194593,\n",
       "             ('kissed',\n",
       "              'half',\n",
       "              'laughing',\n",
       "              'half',\n",
       "              'expurgation'): 0.43859949211194593,\n",
       "             ('half',\n",
       "              'laughing',\n",
       "              'half',\n",
       "              'expurgation',\n",
       "              'mirror'): 0.43859949211194593,\n",
       "             ('laughing',\n",
       "              'half',\n",
       "              'expurgation',\n",
       "              'mirror',\n",
       "              'tilted'): 0.43859949211194593,\n",
       "             ('half',\n",
       "              'expurgation',\n",
       "              'mirror',\n",
       "              'tilted',\n",
       "              'towards'): 0.43859949211194593,\n",
       "             ('expurgation',\n",
       "              'mirror',\n",
       "              'tilted',\n",
       "              'towards',\n",
       "              'the'): 0.43859949211194593,\n",
       "             ('mirror',\n",
       "              'tilted',\n",
       "              'towards',\n",
       "              'the',\n",
       "              'sun'): 0.43859949211194593,\n",
       "             ('tilted', 'towards', 'the', 'sun', '.'): 0.43859949211194593,\n",
       "             ('towards', 'the', 'sun', '.', 'i'): 0.30488135779245923,\n",
       "             ('the', 'sun', '.', 'i', 'dance'): 0.07002926464440201,\n",
       "             ('sun', '.', 'i', 'dance', 'a'): 0.43859949211194593,\n",
       "             ('.', 'i', 'dance', 'a', 'century'): 0.43859949211194593,\n",
       "             ('i', 'dance', 'a', 'century', 'after'): 0.43859949211194593,\n",
       "             ('dance', 'a', 'century', 'after', 'her'): 0.43859949211194593,\n",
       "             ('a', 'century', 'after', 'her', 'song'): 0.43859949211194593,\n",
       "             ('century', 'after', 'her', 'song', '.'): 0.43859949211194593,\n",
       "             ('after', 'her', 'song', '.', 'i'): 0.43859949211194593,\n",
       "             ('her', 'song', '.', 'i', 'am'): 0.43859949211194593,\n",
       "             ('song', '.', 'i', 'am', 'a'): 0.30488135779245923,\n",
       "             ('.', 'i', 'am', 'a', 'sapling'): 0.015803089853149564,\n",
       "             ('i', 'am', 'a', 'sapling', 'old'): 0.43859949211194593,\n",
       "             ('am', 'a', 'sapling', 'old', 'enough'): 0.43859949211194593,\n",
       "             ('a', 'sapling', 'old', 'enough', 'to'): 0.43859949211194593,\n",
       "             ('sapling', 'old', 'enough', 'to', 'cast'): 0.43859949211194593,\n",
       "             ('old', 'enough', 'to', 'cast', 'a'): 0.43859949211194593,\n",
       "             ('enough', 'to', 'cast', 'a', 'shadow'): 0.43859949211194593,\n",
       "             ('to', 'cast', 'a', 'shadow', 'i'): 0.43859949211194593,\n",
       "             ('cast', 'a', 'shadow', 'i', 'am'): 0.43859949211194593,\n",
       "             ('a', 'shadow', 'i', 'am', 'the'): 0.43859949211194593,\n",
       "             ('shadow', 'i', 'am', 'the', 'tree'): 0.43859949211194593,\n",
       "             ('i', 'am', 'the', 'tree', 'pulling'): 0.30488135779245923,\n",
       "             ('am', 'the', 'tree', 'pulling', 'sap'): 0.43859949211194593,\n",
       "             ('the', 'tree', 'pulling', 'sap', 'up'): 0.43859949211194593,\n",
       "             ('tree', 'pulling', 'sap', 'up', 'my'): 0.43859949211194593,\n",
       "             ('pulling', 'sap', 'up', 'my', 'body'): 0.43859949211194593,\n",
       "             ('sap', 'up', 'my', 'body', 'to'): 0.43859949211194593,\n",
       "             ('up', 'my', 'body', 'to', 'nourish'): 0.43859949211194593,\n",
       "             ('my', 'body', 'to', 'nourish', 'sprouting'): 0.43859949211194593,\n",
       "             ('body',\n",
       "              'to',\n",
       "              'nourish',\n",
       "              'sprouting',\n",
       "              'leaves'): 0.43859949211194593,\n",
       "             ('to',\n",
       "              'nourish',\n",
       "              'sprouting',\n",
       "              'leaves',\n",
       "              'for'): 0.43859949211194593,\n",
       "             ('nourish',\n",
       "              'sprouting',\n",
       "              'leaves',\n",
       "              'for',\n",
       "              'spring'): 0.43859949211194593,\n",
       "             ('sprouting',\n",
       "              'leaves',\n",
       "              'for',\n",
       "              'spring',\n",
       "              'i'): 0.43859949211194593,\n",
       "             ('leaves', 'for', 'spring', 'i', 'am'): 0.43859949211194593,\n",
       "             ('for', 'spring', 'i', 'am', 'flowing'): 0.43859949211194593,\n",
       "             ('spring', 'i', 'am', 'flowing', 'water'): 0.43859949211194593,\n",
       "             ('i', 'am', 'flowing', 'water', 'i'): 0.43859949211194593,\n",
       "             ('am', 'flowing', 'water', 'i', 'am'): 0.43859949211194593,\n",
       "             ('flowing', 'water', 'i', 'am', 'a'): 0.43859949211194593,\n",
       "             ('water', 'i', 'am', 'a', 'community'): 0.43859949211194593,\n",
       "             ('i', 'am', 'a', 'community', 'garden'): 0.43859949211194593,\n",
       "             ('am',\n",
       "              'a',\n",
       "              'community',\n",
       "              'garden',\n",
       "              'overrun'): 0.43859949211194593,\n",
       "             ('a',\n",
       "              'community',\n",
       "              'garden',\n",
       "              'overrun',\n",
       "              'by'): 0.43859949211194593,\n",
       "             ('community',\n",
       "              'garden',\n",
       "              'overrun',\n",
       "              'by',\n",
       "              'aphids'): 0.43859949211194593,\n",
       "             ('garden', 'overrun', 'by', 'aphids', 'in'): 0.43859949211194593,\n",
       "             ('overrun', 'by', 'aphids', 'in', 'bloom'): 0.43859949211194593,\n",
       "             ('by', 'aphids', 'in', 'bloom', 'one'): 0.43859949211194593,\n",
       "             ('aphids', 'in', 'bloom', 'one', 'day'): 0.43859949211194593,\n",
       "             ('in', 'bloom', 'one', 'day', 'i'): 0.43859949211194593,\n",
       "             ('bloom', 'one', 'day', 'i', 'decay'): 0.43859949211194593,\n",
       "             ('one', 'day', 'i', 'decay', 'and'): 0.43859949211194593,\n",
       "             ('day', 'i', 'decay', 'and', 'the'): 0.43859949211194593,\n",
       "             ('i', 'decay', 'and', 'the', 'next'): 0.43859949211194593,\n",
       "             ('decay', 'and', 'the', 'next', 'i'): 0.43859949211194593,\n",
       "             ('and', 'the', 'next', 'i', 'am'): 0.43859949211194593,\n",
       "             ('the', 'next', 'i', 'am', 'the'): 0.43859949211194593,\n",
       "             ('next', 'i', 'am', 'the', 'moon'): 0.43859949211194593,\n",
       "             ('i', 'am', 'the', 'moon', 'i'): 0.43859949211194593,\n",
       "             ('am', 'the', 'moon', 'i', 'am'): 0.43859949211194593,\n",
       "             ('the', 'moon', 'i', 'am', 'mountain'): 0.43859949211194593,\n",
       "             ('moon', 'i', 'am', 'mountain', 'my'): 0.43859949211194593,\n",
       "             ('i', 'am', 'mountain', 'my', 'tears'): 0.43859949211194593,\n",
       "             ('am', 'mountain', 'my', 'tears', 'flow'): 0.43859949211194593,\n",
       "             ('mountain', 'my', 'tears', 'flow', 'from'): 0.43859949211194593,\n",
       "             ('my', 'tears', 'flow', 'from', 'bare'): 0.43859949211194593,\n",
       "             ('tears', 'flow', 'from', 'bare', 'stone'): 0.43859949211194593,\n",
       "             ('flow', 'from', 'bare', 'stone', 'my'): 0.43859949211194593,\n",
       "             ('from', 'bare', 'stone', 'my', 'body'): 0.43859949211194593,\n",
       "             ('bare', 'stone', 'my', 'body', 'is'): 0.43859949211194593,\n",
       "             ('stone', 'my', 'body', 'is', 'rock'): 0.43859949211194593,\n",
       "             ('my', 'body', 'is', 'rock', 'and'): 0.43859949211194593,\n",
       "             ('body', 'is', 'rock', 'and', 'dust'): 0.43859949211194593,\n",
       "             ('is', 'rock', 'and', 'dust', 'i'): 0.43859949211194593,\n",
       "             ('rock', 'and', 'dust', 'i', 'am'): 0.43859949211194593,\n",
       "             ('and', 'dust', 'i', 'am', 'ascendant'): 0.43859949211194593,\n",
       "             ('dust', 'i', 'am', 'ascendant', 'the'): 0.43859949211194593,\n",
       "             ('i', 'am', 'ascendant', 'the', 'sky'): 0.43859949211194593,\n",
       "             ('am', 'ascendant', 'the', 'sky', 'i'): 0.43859949211194593,\n",
       "             ('ascendant', 'the', 'sky', 'i', 'want'): 0.43859949211194593,\n",
       "             ('the', 'sky', 'i', 'want', 'is'): 0.43859949211194593,\n",
       "             ('sky', 'i', 'want', 'is', 'blue'): 0.43859949211194593,\n",
       "             ('i', 'want', 'is', 'blue', '.'): 0.43859949211194593,\n",
       "             ('want', 'is', 'blue', '.', 'a'): 0.43859949211194593,\n",
       "             ('is', 'blue', '.', 'a', 'note'): 0.43859949211194593,\n",
       "             ('blue', '.', 'a', 'note', 'this'): 0.43859949211194593,\n",
       "             ('.', 'a', 'note', 'this', 'cento'): 0.43859949211194593,\n",
       "             ('a', 'note', 'this', 'cento', 'features'): 0.43859949211194593,\n",
       "             ('note', 'this', 'cento', 'features', 'at'): 0.43859949211194593,\n",
       "             ('this', 'cento', 'features', 'at', 'least'): 0.43859949211194593,\n",
       "             ('cento', 'features', 'at', 'least', 'one'): 0.43859949211194593,\n",
       "             ('features', 'at', 'least', 'one', 'line'): 0.43859949211194593,\n",
       "             ('at', 'least', 'one', 'line', 'from'): 0.43859949211194593,\n",
       "             ('least', 'one', 'line', 'from', 'every'): 0.43859949211194593,\n",
       "             ('one', 'line', 'from', 'every', 'writer'): 0.43859949211194593,\n",
       "             ('line', 'from', 'every', 'writer', 'whose'): 0.43859949211194593,\n",
       "             ('from', 'every', 'writer', 'whose', 'work'): 0.43859949211194593,\n",
       "             ('every',\n",
       "              'writer',\n",
       "              'whose',\n",
       "              'work',\n",
       "              'appears'): 0.43859949211194593,\n",
       "             ('writer', 'whose', 'work', 'appears', 'in'): 0.43859949211194593,\n",
       "             ('whose', 'work', 'appears', 'in', 'i'): 0.43859949211194593,\n",
       "             ('work', 'appears', 'in', 'i', 'want'): 0.43859949211194593,\n",
       "             ('appears', 'in', 'i', 'want', 'sky'): 0.43859949211194593,\n",
       "             ('in', 'i', 'want', 'sky', ','): 0.43859949211194593,\n",
       "             ('i', 'want', 'sky', ',', 'a'): 0.43859949211194593,\n",
       "             ('want', 'sky', ',', 'a', 'journal'): 0.43859949211194593,\n",
       "             ('sky', ',', 'a', 'journal', 'the'): 0.43859949211194593,\n",
       "             (',', 'a', 'journal', 'the', 'author'): 0.43859949211194593,\n",
       "             ('a', 'journal', 'the', 'author', 'edited'): 0.43859949211194593,\n",
       "             ('journal',\n",
       "              'the',\n",
       "              'author',\n",
       "              'edited',\n",
       "              'celebrating'): 0.43859949211194593,\n",
       "             ('the',\n",
       "              'author',\n",
       "              'edited',\n",
       "              'celebrating',\n",
       "              'sarah'): 0.43859949211194593,\n",
       "             ('author',\n",
       "              'edited',\n",
       "              'celebrating',\n",
       "              'sarah',\n",
       "              'hegazy'): 0.43859949211194593,\n",
       "             ('edited',\n",
       "              'celebrating',\n",
       "              'sarah',\n",
       "              'hegazy',\n",
       "              'and'): 0.43859949211194593,\n",
       "             ('celebrating',\n",
       "              'sarah',\n",
       "              'hegazy',\n",
       "              'and',\n",
       "              'queer'): 0.43859949211194593,\n",
       "             ('sarah', 'hegazy', 'and', 'queer', 'swana'): 0.43859949211194593,\n",
       "             ('hegazy', 'and', 'queer', 'swana', 'life'): 0.43859949211194593,\n",
       "             ('and', 'queer', 'swana', 'life', ','): 0.43859949211194593,\n",
       "             ('queer', 'swana', 'life', ',', 'edited'): 0.43859949211194593,\n",
       "             ('swana', 'life', ',', 'edited', 'by'): 0.43859949211194593,\n",
       "             ('life', ',', 'edited', 'by', 'bazeed'): 0.43859949211194593,\n",
       "             (',', 'edited', 'by', 'bazeed', 'and'): 0.43859949211194593,\n",
       "             ('edited',\n",
       "              'by',\n",
       "              'bazeed',\n",
       "              'and',\n",
       "              'co-published'): 0.43859949211194593,\n",
       "             ('by',\n",
       "              'bazeed',\n",
       "              'and',\n",
       "              'co-published',\n",
       "              'in'): 0.43859949211194593,\n",
       "             ('bazeed',\n",
       "              'and',\n",
       "              'co-published',\n",
       "              'in',\n",
       "              'by'): 0.43859949211194593,\n",
       "             ('and', 'co-published', 'in', 'by', 'the'): 0.43859949211194593,\n",
       "             ('co-published', 'in', 'by', 'the', 'asian'): 0.43859949211194593,\n",
       "             ('in', 'by', 'the', 'asian', 'american'): 0.43859949211194593,\n",
       "             ('by',\n",
       "              'the',\n",
       "              'asian',\n",
       "              'american',\n",
       "              'writers'): 0.43859949211194593,\n",
       "             ('the',\n",
       "              'asian',\n",
       "              'american',\n",
       "              'writers',\n",
       "              'workshop'): 0.43859949211194593,\n",
       "             ('asian',\n",
       "              'american',\n",
       "              'writers',\n",
       "              'workshop',\n",
       "              'and'): 0.43859949211194593,\n",
       "             ('american',\n",
       "              'writers',\n",
       "              'workshop',\n",
       "              'and',\n",
       "              'mizna.to'): 0.43859949211194593,\n",
       "             ('writers',\n",
       "              'workshop',\n",
       "              'and',\n",
       "              'mizna.to',\n",
       "              'name'): 0.43859949211194593,\n",
       "             ('workshop',\n",
       "              'and',\n",
       "              'mizna.to',\n",
       "              'name',\n",
       "              'and'): 0.43859949211194593,\n",
       "             ('and', 'mizna.to', 'name', 'and', 'thank'): 0.43859949211194593,\n",
       "             ('mizna.to', 'name', 'and', 'thank', 'them'): 0.43859949211194593,\n",
       "             ('name', 'and', 'thank', 'them', 'for'): 0.43859949211194593,\n",
       "             ('and', 'thank', 'them', 'for', 'words'): 0.43859949211194593,\n",
       "             ('thank', 'them', 'for', 'words', 'ripe'): 0.43859949211194593,\n",
       "             ('them', 'for', 'words', 'ripe', 'for'): 0.43859949211194593,\n",
       "             ('for',\n",
       "              'words',\n",
       "              'ripe',\n",
       "              'for',\n",
       "              'stealingmad'): 0.43859949211194593,\n",
       "             ('words', 'ripe', 'for', 'stealingmad', ','): 0.43859949211194593,\n",
       "             ('ripe', 'for', 'stealingmad', ',', 'ama'): 0.43859949211194593,\n",
       "             ('for', 'stealingmad', ',', 'ama', ','): 0.43859949211194593,\n",
       "             ('stealingmad', ',', 'ama', ',', 'amir'): 0.43859949211194593,\n",
       "             (',', 'ama', ',', 'amir', 'ferdjani'): 0.43859949211194593,\n",
       "             ('ama', ',', 'amir', 'ferdjani', ','): 0.43859949211194593,\n",
       "             (',', 'amir', 'ferdjani', ',', 'banah'): 0.43859949211194593,\n",
       "             ('amir',\n",
       "              'ferdjani',\n",
       "              ',',\n",
       "              'banah',\n",
       "              'elghadbanah'): 0.43859949211194593,\n",
       "             ('ferdjani',\n",
       "              ',',\n",
       "              'banah',\n",
       "              'elghadbanah',\n",
       "              ','): 0.43859949211194593,\n",
       "             (',', 'banah', 'elghadbanah', ',', 'donia'): 0.43859949211194593,\n",
       "             ('banah',\n",
       "              'elghadbanah',\n",
       "              ',',\n",
       "              'donia',\n",
       "              'salemharhoor'): 0.43859949211194593,\n",
       "             ('elghadbanah',\n",
       "              ',',\n",
       "              'donia',\n",
       "              'salemharhoor',\n",
       "              ','): 0.43859949211194593,\n",
       "             (',', 'donia', 'salemharhoor', ',', 'eman'): 0.43859949211194593,\n",
       "             ('donia',\n",
       "              'salemharhoor',\n",
       "              ',',\n",
       "              'eman',\n",
       "              'desouky'): 0.43859949211194593,\n",
       "             ('salemharhoor',\n",
       "              ',',\n",
       "              'eman',\n",
       "              'desouky',\n",
       "              ','): 0.43859949211194593,\n",
       "             (',', 'eman', 'desouky', ',', 'gamal'): 0.43859949211194593,\n",
       "             ('eman', 'desouky', ',', 'gamal', 'elsawah'): 0.43859949211194593,\n",
       "             ('desouky', ',', 'gamal', 'elsawah', ','): 0.43859949211194593,\n",
       "             (',', 'gamal', 'elsawah', ',', 'ghinwa'): 0.43859949211194593,\n",
       "             ('gamal',\n",
       "              'elsawah',\n",
       "              ',',\n",
       "              'ghinwa',\n",
       "              'jawhari'): 0.43859949211194593,\n",
       "             ('elsawah', ',', 'ghinwa', 'jawhari', ','): 0.43859949211194593,\n",
       "             (',', 'ghinwa', 'jawhari', ',', 'janine'): 0.43859949211194593,\n",
       "             ('ghinwa',\n",
       "              'jawhari',\n",
       "              ',',\n",
       "              'janine',\n",
       "              'mogannam'): 0.43859949211194593,\n",
       "             ('jawhari', ',', 'janine', 'mogannam', ','): 0.43859949211194593,\n",
       "             (',', 'janine', 'mogannam', ',', 'kamelya'): 0.43859949211194593,\n",
       "             ('janine',\n",
       "              'mogannam',\n",
       "              ',',\n",
       "              'kamelya',\n",
       "              'omayma'): 0.43859949211194593,\n",
       "             ('mogannam',\n",
       "              ',',\n",
       "              'kamelya',\n",
       "              'omayma',\n",
       "              'youssef'): 0.43859949211194593,\n",
       "             (',', 'kamelya', 'omayma', 'youssef', ','): 0.43859949211194593,\n",
       "             ('kamelya',\n",
       "              'omayma',\n",
       "              'youssef',\n",
       "              ',',\n",
       "              'layla'): 0.43859949211194593,\n",
       "             ('omayma',\n",
       "              'youssef',\n",
       "              ',',\n",
       "              'layla',\n",
       "              'zbinden'): 0.43859949211194593,\n",
       "             ('youssef', ',', 'layla', 'zbinden', ','): 0.43859949211194593,\n",
       "             (',', 'layla', 'zbinden', ',', 'mejdulene'): 0.43859949211194593,\n",
       "             ('layla', 'zbinden', ',', 'mejdulene', 'b.'): 0.43859949211194593,\n",
       "             ('zbinden',\n",
       "              ',',\n",
       "              'mejdulene',\n",
       "              'b.',\n",
       "              'shomali'): 0.43859949211194593,\n",
       "             (',', 'mejdulene', 'b.', 'shomali', ','): 0.43859949211194593,\n",
       "             ('mejdulene', 'b.', 'shomali', ',', 'mish'): 0.43859949211194593,\n",
       "             ('b.', 'shomali', ',', 'mish', 'ismy'): 0.43859949211194593,\n",
       "             ('shomali', ',', 'mish', 'ismy', ','): 0.43859949211194593,\n",
       "             (',', 'mish', 'ismy', ',', 'nada'): 0.43859949211194593,\n",
       "             ('mish', 'ismy', ',', 'nada', 'almosa'): 0.43859949211194593,\n",
       "             ('ismy', ',', 'nada', 'almosa', ','): 0.43859949211194593,\n",
       "             (',', 'nada', 'almosa', ',', 'niki'): 0.43859949211194593,\n",
       "             ('nada', 'almosa', ',', 'niki', 'afsar'): 0.43859949211194593,\n",
       "             ('almosa', ',', 'niki', 'afsar', ','): 0.43859949211194593,\n",
       "             (',', 'niki', 'afsar', ',', 'nour'): 0.43859949211194593,\n",
       "             ('niki', 'afsar', ',', 'nour', 'kamel'): 0.43859949211194593,\n",
       "             ('afsar', ',', 'nour', 'kamel', ','): 0.43859949211194593,\n",
       "             (',', 'nour', 'kamel', ',', 'nusaiba'): 0.43859949211194593,\n",
       "             ('nour', 'kamel', ',', 'nusaiba', 'imady'): 0.43859949211194593,\n",
       "             ('kamel', ',', 'nusaiba', 'imady', ','): 0.43859949211194593,\n",
       "             (',', 'nusaiba', 'imady', ',', 'qais'): 0.43859949211194593,\n",
       "             ('nusaiba', 'imady', ',', 'qais', 'kamran'): 0.43859949211194593,\n",
       "             ('imady', ',', 'qais', 'kamran', ','): 0.43859949211194593,\n",
       "             (',', 'qais', 'kamran', ',', 'shiyam'): 0.43859949211194593,\n",
       "             ('qais', 'kamran', ',', 'shiyam', 'galyon'): 0.43859949211194593,\n",
       "             ('kamran', ',', 'shiyam', 'galyon', ','): 0.43859949211194593,\n",
       "             (',', 'shiyam', 'galyon', ',', 'and'): 0.43859949211194593,\n",
       "             ('shiyam', 'galyon', ',', 'and', 'walid'): 0.43859949211194593,\n",
       "             ('galyon', ',', 'and', 'walid', 'daou'): 0.43859949211194593,\n",
       "             (',', 'and', 'walid', 'daou', '.'): 0.43859949211194593,\n",
       "             ('and', 'walid', 'daou', '.', 'the'): 0.43859949211194593,\n",
       "             ('walid', 'daou', '.', 'the', 'lines'): 0.43859949211194593,\n",
       "             ('daou', '.', 'the', 'lines', 'of'): 0.43859949211194593,\n",
       "             ('.', 'the', 'lines', 'of', 'arabic'): 0.23364789499139027,\n",
       "             ('the', 'lines', 'of', 'arabic', 'that'): 0.43859949211194593,\n",
       "             ('lines', 'of', 'arabic', 'that', 'appear'): 0.43859949211194593,\n",
       "             ('of', 'arabic', 'that', 'appear', 'in'): 0.43859949211194593,\n",
       "             ('arabic', 'that', 'appear', 'in', 'the'): 0.43859949211194593,\n",
       "             ('that', 'appear', 'in', 'the', 'cento'): 0.43859949211194593,\n",
       "             ('appear', 'in', 'the', 'cento', 'are'): 0.43859949211194593,\n",
       "             ('in', 'the', 'cento', 'are', 'either'): 0.43859949211194593,\n",
       "             ('the',\n",
       "              'cento',\n",
       "              'are',\n",
       "              'either',\n",
       "              'immediately'): 0.43859949211194593,\n",
       "             ('cento',\n",
       "              'are',\n",
       "              'either',\n",
       "              'immediately',\n",
       "              'preceded'): 0.43859949211194593,\n",
       "             ('are',\n",
       "              'either',\n",
       "              'immediately',\n",
       "              'preceded',\n",
       "              'or'): 0.43859949211194593,\n",
       "             ...})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(test_tokens, ngram_probabilities, n):\n",
    "    \"\"\"Calculates the perplexity of a test corpus given n-gram probabilities.\"\"\"\n",
    "    log_probability_sum = 0\n",
    "    ngram_count = 0\n",
    "    \n",
    "    for i in range(len(test_tokens)-n+1):\n",
    "        ngram = tuple(test_tokens[i:i+n])\n",
    "        log_probability_sum += math.log2(ngram_probabilities[ngram])\n",
    "        ngram_count += 1\n",
    "    \n",
    "    average_log_probability = -log_probability_sum / ngram_count\n",
    "    perplexity = math.pow(2, average_log_probability)\n",
    "    \n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.348875864416577"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_perplexity(tokens, ngram_probabilities, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_sampling(context, vocab, ngram_probabilities, n, max_length = 50):\n",
    "    \n",
    "    sentence = []\n",
    "\n",
    "    if len(context) < (n-1):\n",
    "        print(\"len(context) < n\")\n",
    "        return sentence\n",
    "\n",
    "    context = context[-(n-1):]\n",
    "    \n",
    "    for i in range(max_length):\n",
    "\n",
    "        probs = dict()\n",
    "        \n",
    "        for v in vocab:\n",
    "\n",
    "            ngram = list(context)\n",
    "            ngram.append(v)\n",
    "            ngram = tuple(ngram)\n",
    "            probs[v] = ngram_probabilities[ngram]\n",
    "\n",
    "        best_token = max(probs, key=probs.get) # greedy \n",
    "        #print(best_v)\n",
    "        #print(probs[best_v])\n",
    "        \n",
    "        if probs[best_token] == 0:\n",
    "            print(\"prob = 0\")\n",
    "            return sentence\n",
    "            \n",
    "        sentence.append(best_token)\n",
    "        context = list(context)[1:]\n",
    "        context.append(best_token)\n",
    "        context = tuple(context)\n",
    "            \n",
    "    return sentence  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram :\n",
      "\n",
      "prob = 0\n",
      "perplexity: 1180.0935812227215\n",
      "in \n",
      "\n",
      "\n",
      "2-gram :\n",
      "\n",
      "perplexity: 142.03690641192838\n",
      "in the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the\n",
      "\n",
      "\n",
      "3-gram :\n",
      "\n",
      "perplexity: 13.323716982780782\n",
      "in the dark , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world\n",
      "\n",
      "\n",
      "4-gram :\n",
      "\n",
      "perplexity: 3.23438254264985\n",
      "in the dark we 've only touched the tip of a sharp blade of steel cutting through air singing as it slices a head clean from its neck you watch it drop heavily as a rock , a rip in the fabric of the ongoing forest from which rises as he tries to remember snow noise . would powder snow ping like that ? it 's not that i was altogether such a one as thyself . david , psalms . thou thoughtest that i was altogether such a one as thyself . david , psalms . thou thoughtest that i was altogether such a one as thyself . david , psalms . thou thoughtest that i was altogether such a one as thyself . david , psalms . thou thoughtest that i was altogether such a one as thyself . david , psalms . thou thoughtest that i was altogether such a one as thyself . david , psalms . thou thoughtest that i was altogether such a one as thyself . david , psalms . thou thoughtest that i was altogether such a one as thyself . david , psalms . thou thoughtest that i was altogether such a one as thyself\n",
      "\n",
      "\n",
      "5-gram :\n",
      "\n",
      "perplexity: 2.348875864416577\n",
      "in the dark we disappear , pure being . our mirror images , impure being . being and becoming heidegger , being and nothingness sartrewhich is purer being ? being alone is no way to think the wedding of your lips with mine ; imagination makes no magic to match the roaring wonder of you close to me ; and now that you have no crumbs , donteven have pockets to turn outonly the memoryof such acts , such things . how weary , stale , and profligate it seems to be to plasticize theselines . youre in a hamless state of mind . now get out and talk to anyone your age like you theyve all got death studded on the tongue , which livelies up the talk they walk . approach life as if it were a house window.or something from an office block.it does not create or stain but gives an outsidefalling past sainsburys and the sander towerlooming , then the ring road communionedtraffic forming . an open roompupiled towards rain in its rain-tone , the study of an unaltared sun . praise the restless beds praise the beds that do not adjust that wo n't lift the head to feed or\n",
      "\n",
      "\n",
      "6-gram :\n",
      "\n",
      "perplexity: 2.252009183449726\n",
      "in the dark we disappear , pure being . our mirror images , impure being . being and becoming heidegger , being and nothingness sartrewhich is purer being ? being alone is no way to be thus loneliness is the test of pure being . nights in love i fell too far or not quite far enoughone pure , one impure being . clouds , snow , mist , the dragon 's breath on water , smoke from firea metaphor 's pure being . stillness and more stillness and the light locked deep insideboth pure and impure being . is is the verb of being , i the noun or pronoun for the purists of being . i was , i am , i am here , brushes clamped , soap and water pulsing against my car . a good sign too , those asylums for old and diseased animals . my car is clean and no one has had to lift a finger . the dead bugs have been gushed away into a soup of grit and foamthe evidence not subterranean , not streaming along the asphalt in sunlight so dazzling i attend the birth-moment of the word hosannah ! i care about the\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = ['in', 'the', 'dark', 'we','disappear']\n",
    "n_values = range(1, 7)  # Iterate n from 1 to 6\n",
    "for n in n_values:\n",
    "    print(f\"{n}-gram :\\n\")\n",
    "    k = 0.00001  # Smoothing parameter k\n",
    "    \n",
    "    # Calculate n-gram probabilities\n",
    "    ngram_probabilities = calculate_ngram_probabilities(df, 'poem', n, k)\n",
    "    \n",
    "    # Generate sentence using greedy sampling\n",
    "    sentence = greedy_sampling(context[:n], vocab, ngram_probabilities, n, max_length=200)\n",
    "    \n",
    "    # Print the context and generated sentence\n",
    "    print(\"perplexity: \" + f'{calculate_perplexity(tokens, ngram_probabilities, n)}')\n",
    "    print(\" \".join(context[:n]) + \" \" + \" \".join(sentence))\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
