{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8429595,"sourceType":"datasetVersion","datasetId":5019846}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n\n# Assuming you already have a DataFrame with columns 'poem' and 'topic'\n# Load your DataFrame\ndf = pd.read_csv(\"/kaggle/input/poem-classification-dataset/data.csv\")\n\n# Save the poems to a text file, required for training\nwith open('poems.txt', 'w') as f:\n    for poem in df['poem']:\n        f.write(poem + '\\n\\n')\n\n# Load the tokenizer and model\nmodel_name = 'gpt2'\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\nmodel = GPT2LMHeadModel.from_pretrained(model_name)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-17T22:20:20.675690Z","iopub.execute_input":"2024-05-17T22:20:20.676556Z","iopub.status.idle":"2024-05-17T22:20:43.970977Z","shell.execute_reply.started":"2024-05-17T22:20:20.676509Z","shell.execute_reply":"2024-05-17T22:20:43.970057Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-17 22:20:30.265305: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-17 22:20:30.265413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-17 22:20:30.391444: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"954c065ef1f44b71a46e7247d4b73422"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48e81290cab44a14bf0558ec391a77bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b10e740c3cc24f47b869388d3ff7a649"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16b16d55c9d3405c82666e22b49bbe1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"030fca193791457ea837a0770d53c60a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03ef16a8d6e04e1284dbaa1cabe7560f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"957d892b7db446feac4ca54146996eac"}},"metadata":{}}]},{"cell_type":"code","source":"# Create a dataset from the poems text file\ndef load_dataset(file_path, tokenizer, block_size=128):\n    dataset = TextDataset(\n        tokenizer=tokenizer,\n        file_path=file_path,\n        block_size=block_size,\n    )\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:20:43.972746Z","iopub.execute_input":"2024-05-17T22:20:43.973022Z","iopub.status.idle":"2024-05-17T22:20:43.977676Z","shell.execute_reply.started":"2024-05-17T22:20:43.972998Z","shell.execute_reply":"2024-05-17T22:20:43.976832Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_dataset = load_dataset('/kaggle/working/poems.txt', tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:20:43.978819Z","iopub.execute_input":"2024-05-17T22:20:43.979105Z","iopub.status.idle":"2024-05-17T22:21:25.931845Z","shell.execute_reply.started":"2024-05-17T22:20:43.979083Z","shell.execute_reply":"2024-05-17T22:21:25.930857Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a data collator\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:21:25.934300Z","iopub.execute_input":"2024-05-17T22:21:25.935034Z","iopub.status.idle":"2024-05-17T22:21:25.939279Z","shell.execute_reply.started":"2024-05-17T22:21:25.935000Z","shell.execute_reply":"2024-05-17T22:21:25.938356Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    overwrite_output_dir=True,\n    num_train_epochs=1,\n    per_device_train_batch_size=4,\n    save_steps=10_000,\n    save_total_limit=2,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:21:25.941156Z","iopub.execute_input":"2024-05-17T22:21:25.941525Z","iopub.status.idle":"2024-05-17T22:21:26.023112Z","shell.execute_reply.started":"2024-05-17T22:21:25.941492Z","shell.execute_reply":"2024-05-17T22:21:26.022281Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Create the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:21:26.024195Z","iopub.execute_input":"2024-05-17T22:21:26.024479Z","iopub.status.idle":"2024-05-17T22:21:27.220383Z","shell.execute_reply.started":"2024-05-17T22:21:26.024456Z","shell.execute_reply":"2024-05-17T22:21:27.219647Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"## Fine-tune the model\nimport os\nos.environ['WANDB_MODE'] = 'disabled'\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:45:23.494806Z","iopub.execute_input":"2024-05-17T22:45:23.495626Z","iopub.status.idle":"2024-05-17T23:00:23.209217Z","shell.execute_reply.started":"2024-05-17T22:45:23.495595Z","shell.execute_reply":"2024-05-17T23:00:23.208434Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8892' max='8892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8892/8892 14:59, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>4.040800</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>4.062100</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>4.047000</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>4.070900</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>4.070800</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>4.066300</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>4.101100</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>4.086500</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>4.059300</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>4.077800</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>4.117900</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>4.094500</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>4.118600</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>4.118500</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>4.117700</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>4.134800</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>4.124100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=8892, training_loss=4.089257367709387, metrics={'train_runtime': 899.2714, 'train_samples_per_second': 39.552, 'train_steps_per_second': 9.888, 'total_flos': 2323408748544000.0, 'train_loss': 4.089257367709387, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"./result_train2\")\ntokenizer.save_pretrained(\"./result_train2\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:00:23.210841Z","iopub.execute_input":"2024-05-17T23:00:23.211122Z","iopub.status.idle":"2024-05-17T23:00:24.387256Z","shell.execute_reply.started":"2024-05-17T23:00:23.211099Z","shell.execute_reply":"2024-05-17T23:00:24.386349Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"('./result_train2/tokenizer_config.json',\n './result_train2/special_tokens_map.json',\n './result_train2/vocab.json',\n './result_train2/merges.txt',\n './result_train2/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"# Load the fine-tuned model for generation\nmodel = GPT2LMHeadModel.from_pretrained('/kaggle/working/result_train2')\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:00:24.388391Z","iopub.execute_input":"2024-05-17T23:00:24.388656Z","iopub.status.idle":"2024-05-17T23:00:24.956479Z","shell.execute_reply.started":"2024-05-17T23:00:24.388634Z","shell.execute_reply":"2024-05-17T23:00:24.955486Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Function to generate poems from a prompt\ndef generate_poem(prompt, model, tokenizer, max_length=200, temperature=0.7):\n    inputs = tokenizer.encode(prompt, return_tensors='pt')\n    outputs = model.generate(inputs, max_length=max_length, temperature=temperature, num_return_sequences=1, num_beams=5, no_repeat_ngram_size=2)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:00:55.756642Z","iopub.execute_input":"2024-05-17T23:00:55.757265Z","iopub.status.idle":"2024-05-17T23:00:55.762469Z","shell.execute_reply.started":"2024-05-17T23:00:55.757236Z","shell.execute_reply":"2024-05-17T23:00:55.761573Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Example usage\nprompt = \"Long live the king\"\ngenerated_poem = generate_poem(prompt, model, tokenizer)\nprint(generated_poem)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:01:56.833428Z","iopub.execute_input":"2024-05-17T23:01:56.833801Z","iopub.status.idle":"2024-05-17T23:02:12.988049Z","shell.execute_reply.started":"2024-05-17T23:01:56.833774Z","shell.execute_reply":"2024-05-17T23:02:12.987064Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Long live the king’s blood,\nAnd the blood of his sons.\n\nThe king is dead, and the sons\nAre dead. The king was born\nIn the land of the dead;\nHe was the son of a king\nWho died in his own blood.\n\n\n\n\n(from “The Song of Solomon” by Robert Klee, translated from the Spanish by David S. Lewis, published by the University of California Press, 2001)\n\n                                                 “I have heard the voice of God,          And I have seen the face of Heav'n.                                                 The Lord is in the midst of all things;             He is the King of Israel, the Lord of hosts, The Lord and God of men; He is God and man; and he is good and wise; And he hath power and will.     And He hath the power\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}